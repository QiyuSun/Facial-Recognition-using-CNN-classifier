{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54de18e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 470543 images belonging to 1595 classes.\n",
      "Found 119313 images belonging to 1595 classes.\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir = 'D:\\\\aligned_images_DB_dataset\\\\train'\n",
    "validation_dir = 'D:\\\\aligned_images_DB_dataset\\\\validation'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory = train_dir,\n",
    "        target_size=(152, 152),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        directory = validation_dir,\n",
    "        target_size=(152, 152),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e70a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steve\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[   0    1    2 ... 1592 1593 1594], y=[   0    0    0 ... 1594 1594 1594] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\steve\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/200\n",
      "50/50 [==============================] - 4246s 86s/step - loss: 15.9016 - acc: 0.0119 - val_loss: 13.3737 - val_acc: 0.0215\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - 480s 10s/step - loss: 13.2690 - acc: 0.0237 - val_loss: 12.6549 - val_acc: 0.0306\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 1250s 25s/step - loss: 12.9406 - acc: 0.0362 - val_loss: 12.3290 - val_acc: 0.0407\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 641s 13s/step - loss: 12.7244 - acc: 0.0475 - val_loss: 12.0441 - val_acc: 0.0404\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - 394s 8s/step - loss: 12.3104 - acc: 0.0531 - val_loss: 11.8470 - val_acc: 0.0581\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - 383s 8s/step - loss: 12.3935 - acc: 0.0469 - val_loss: 11.4980 - val_acc: 0.0647\n",
      "Epoch 7/200\n",
      "50/50 [==============================] - 381s 8s/step - loss: 12.3356 - acc: 0.0631 - val_loss: 11.1401 - val_acc: 0.0772\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - 382s 8s/step - loss: 11.6071 - acc: 0.0688 - val_loss: 10.9564 - val_acc: 0.0960\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - 382s 8s/step - loss: 11.7682 - acc: 0.0838 - val_loss: 10.7696 - val_acc: 0.1142\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - 382s 8s/step - loss: 11.2796 - acc: 0.1088 - val_loss: 10.4373 - val_acc: 0.0992\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - 381s 8s/step - loss: 11.2404 - acc: 0.1225 - val_loss: 10.2863 - val_acc: 0.1098\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - 381s 8s/step - loss: 11.4277 - acc: 0.1056 - val_loss: 10.1164 - val_acc: 0.1332\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 382s 8s/step - loss: 10.4514 - acc: 0.1344 - val_loss: 9.6535 - val_acc: 0.1629\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - 380s 8s/step - loss: 10.2363 - acc: 0.1637 - val_loss: 9.4839 - val_acc: 0.1942\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - 381s 8s/step - loss: 10.0976 - acc: 0.1562 - val_loss: 9.2040 - val_acc: 0.2034\n",
      "Epoch 16/200\n",
      "50/50 [==============================] - 379s 8s/step - loss: 10.0835 - acc: 0.1844 - val_loss: 8.9543 - val_acc: 0.2178\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - 379s 8s/step - loss: 9.8712 - acc: 0.1925 - val_loss: 8.6843 - val_acc: 0.2523\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - 379s 8s/step - loss: 9.3364 - acc: 0.2281 - val_loss: 8.3959 - val_acc: 0.2752\n",
      "Epoch 19/200\n",
      "50/50 [==============================] - 379s 8s/step - loss: 9.2293 - acc: 0.2394 - val_loss: 8.2814 - val_acc: 0.2810\n",
      "Epoch 20/200\n",
      "50/50 [==============================] - 379s 8s/step - loss: 9.1286 - acc: 0.2788 - val_loss: 7.9230 - val_acc: 0.3273\n",
      "Epoch 21/200\n",
      "50/50 [==============================] - 378s 8s/step - loss: 9.2312 - acc: 0.3031 - val_loss: 8.0463 - val_acc: 0.3042\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - 379s 8s/step - loss: 9.0511 - acc: 0.3088 - val_loss: 7.6933 - val_acc: 0.3279\n",
      "Epoch 23/200\n",
      "50/50 [==============================] - 379s 8s/step - loss: 8.5698 - acc: 0.3056 - val_loss: 7.3554 - val_acc: 0.3643\n",
      "Epoch 24/200\n",
      "50/50 [==============================] - 364s 7s/step - loss: 7.9843 - acc: 0.3381 - val_loss: 7.1276 - val_acc: 0.3962\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 8.2084 - acc: 0.3619 - val_loss: 7.0073 - val_acc: 0.4054\n",
      "Epoch 26/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 7.5870 - acc: 0.3981 - val_loss: 6.7747 - val_acc: 0.4105\n",
      "Epoch 27/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 7.4909 - acc: 0.4025 - val_loss: 6.5048 - val_acc: 0.4502\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 7.5271 - acc: 0.4256 - val_loss: 6.3295 - val_acc: 0.4522\n",
      "Epoch 29/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 7.5012 - acc: 0.4338 - val_loss: 6.1869 - val_acc: 0.4712\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 7.1306 - acc: 0.4462 - val_loss: 5.9326 - val_acc: 0.5031\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - 364s 7s/step - loss: 6.8707 - acc: 0.4387 - val_loss: 5.8250 - val_acc: 0.4962\n",
      "Epoch 32/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 7.0957 - acc: 0.4519 - val_loss: 5.8241 - val_acc: 0.4927\n",
      "Epoch 33/200\n",
      "50/50 [==============================] - 364s 7s/step - loss: 6.6684 - acc: 0.4600 - val_loss: 5.5272 - val_acc: 0.5292\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - 376s 8s/step - loss: 6.3234 - acc: 0.4794 - val_loss: 5.3916 - val_acc: 0.5397\n",
      "Epoch 35/200\n",
      "50/50 [==============================] - 378s 8s/step - loss: 6.1975 - acc: 0.5231 - val_loss: 5.2393 - val_acc: 0.5584\n",
      "Epoch 36/200\n",
      "50/50 [==============================] - 377s 8s/step - loss: 5.9505 - acc: 0.5375 - val_loss: 5.1599 - val_acc: 0.5509\n",
      "Epoch 37/200\n",
      "50/50 [==============================] - 376s 8s/step - loss: 5.2806 - acc: 0.5350 - val_loss: 4.8938 - val_acc: 0.5824\n",
      "Epoch 38/200\n",
      "50/50 [==============================] - 377s 8s/step - loss: 6.1378 - acc: 0.5312 - val_loss: 4.8597 - val_acc: 0.5859\n",
      "Epoch 39/200\n",
      "50/50 [==============================] - 377s 8s/step - loss: 5.3888 - acc: 0.5644 - val_loss: 4.7627 - val_acc: 0.5804\n",
      "Epoch 40/200\n",
      "50/50 [==============================] - 376s 8s/step - loss: 5.1203 - acc: 0.5775 - val_loss: 4.5980 - val_acc: 0.6043\n",
      "Epoch 41/200\n",
      "50/50 [==============================] - 376s 8s/step - loss: 5.5940 - acc: 0.5575 - val_loss: 4.6682 - val_acc: 0.5854\n",
      "Epoch 42/200\n",
      "50/50 [==============================] - 377s 8s/step - loss: 5.0064 - acc: 0.5606 - val_loss: 4.3879 - val_acc: 0.6174\n",
      "Epoch 43/200\n",
      "50/50 [==============================] - 378s 8s/step - loss: 5.1437 - acc: 0.5925 - val_loss: 4.3620 - val_acc: 0.6226\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - 377s 8s/step - loss: 4.6248 - acc: 0.6169 - val_loss: 4.1792 - val_acc: 0.6349\n",
      "Epoch 45/200\n",
      "50/50 [==============================] - 376s 8s/step - loss: 4.5728 - acc: 0.6319 - val_loss: 4.1413 - val_acc: 0.6329\n",
      "Epoch 46/200\n",
      "50/50 [==============================] - 368s 7s/step - loss: 4.8518 - acc: 0.6212 - val_loss: 4.0650 - val_acc: 0.6428\n",
      "Epoch 47/200\n",
      "50/50 [==============================] - 363s 7s/step - loss: 4.8265 - acc: 0.6087 - val_loss: 4.0180 - val_acc: 0.6481\n",
      "Epoch 48/200\n",
      "50/50 [==============================] - 363s 7s/step - loss: 4.4596 - acc: 0.6206 - val_loss: 3.9231 - val_acc: 0.6516\n",
      "Epoch 49/200\n",
      "50/50 [==============================] - 362s 7s/step - loss: 4.3866 - acc: 0.6187 - val_loss: 3.9000 - val_acc: 0.6412\n",
      "Epoch 50/200\n",
      "50/50 [==============================] - 364s 7s/step - loss: 4.3052 - acc: 0.6200 - val_loss: 3.7797 - val_acc: 0.6542\n",
      "Epoch 51/200\n",
      "50/50 [==============================] - 363s 7s/step - loss: 3.7063 - acc: 0.6519 - val_loss: 3.5963 - val_acc: 0.6813\n",
      "Epoch 52/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 4.4750 - acc: 0.6331 - val_loss: 3.6912 - val_acc: 0.6585\n",
      "Epoch 53/200\n",
      "50/50 [==============================] - 375s 8s/step - loss: 3.9155 - acc: 0.6525 - val_loss: 3.5347 - val_acc: 0.6748\n",
      "Epoch 54/200\n",
      "50/50 [==============================] - 375s 8s/step - loss: 3.6959 - acc: 0.6656 - val_loss: 3.3916 - val_acc: 0.6917\n",
      "Epoch 55/200\n",
      "50/50 [==============================] - 375s 8s/step - loss: 3.7146 - acc: 0.6594 - val_loss: 3.3670 - val_acc: 0.6943\n",
      "Epoch 56/200\n",
      "50/50 [==============================] - 374s 8s/step - loss: 3.5939 - acc: 0.6538 - val_loss: 3.2180 - val_acc: 0.7131\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - 375s 8s/step - loss: 3.5825 - acc: 0.6856 - val_loss: 3.2467 - val_acc: 0.7039\n",
      "Epoch 58/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 3.4510 - acc: 0.6850 - val_loss: 3.1974 - val_acc: 0.7029\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - 376s 8s/step - loss: 3.3995 - acc: 0.6944 - val_loss: 3.1309 - val_acc: 0.7092\n",
      "Epoch 60/200\n",
      "50/50 [==============================] - 374s 8s/step - loss: 3.2062 - acc: 0.7075 - val_loss: 3.0361 - val_acc: 0.7159\n",
      "Epoch 61/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 2.8867 - acc: 0.7125 - val_loss: 2.8896 - val_acc: 0.7388\n",
      "Epoch 62/200\n",
      "50/50 [==============================] - 375s 8s/step - loss: 3.1891 - acc: 0.6969 - val_loss: 2.9838 - val_acc: 0.7129\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - 376s 8s/step - loss: 2.9275 - acc: 0.7100 - val_loss: 2.8008 - val_acc: 0.7469\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - 374s 8s/step - loss: 2.7287 - acc: 0.7300 - val_loss: 2.7744 - val_acc: 0.7451\n",
      "Epoch 65/200\n",
      "50/50 [==============================] - 374s 8s/step - loss: 3.0065 - acc: 0.7063 - val_loss: 2.8145 - val_acc: 0.7292\n",
      "Epoch 66/200\n",
      "50/50 [==============================] - 376s 8s/step - loss: 2.7797 - acc: 0.7188 - val_loss: 2.7287 - val_acc: 0.7400\n",
      "Epoch 67/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 2.7972 - acc: 0.7337 - val_loss: 2.6528 - val_acc: 0.7512\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - 374s 8s/step - loss: 2.6951 - acc: 0.7244 - val_loss: 2.6300 - val_acc: 0.7479\n",
      "Epoch 69/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 2.5945 - acc: 0.7419 - val_loss: 2.5419 - val_acc: 0.7616\n",
      "Epoch 70/200\n",
      "50/50 [==============================] - 374s 8s/step - loss: 2.4789 - acc: 0.7544 - val_loss: 2.5148 - val_acc: 0.7552\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 2.6935 - acc: 0.7469 - val_loss: 2.5540 - val_acc: 0.7443\n",
      "Epoch 72/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 2.7053 - acc: 0.7319 - val_loss: 2.5254 - val_acc: 0.7522\n",
      "Epoch 73/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 2.3858 - acc: 0.7525 - val_loss: 2.4018 - val_acc: 0.7702\n",
      "Epoch 74/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 2.3937 - acc: 0.7750 - val_loss: 2.3685 - val_acc: 0.7715\n",
      "Epoch 75/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 2.2943 - acc: 0.7487 - val_loss: 2.3233 - val_acc: 0.7724\n",
      "Epoch 76/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 2.3474 - acc: 0.7588 - val_loss: 2.3262 - val_acc: 0.7706\n",
      "Epoch 77/200\n",
      "50/50 [==============================] - 388s 8s/step - loss: 2.3839 - acc: 0.7681 - val_loss: 2.2767 - val_acc: 0.7779\n",
      "Epoch 78/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 2.2725 - acc: 0.7644 - val_loss: 2.2168 - val_acc: 0.7840\n",
      "Epoch 79/200\n",
      "50/50 [==============================] - 374s 8s/step - loss: 2.2760 - acc: 0.7594 - val_loss: 2.2863 - val_acc: 0.7619\n",
      "Epoch 80/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 2.2293 - acc: 0.7525 - val_loss: 2.1618 - val_acc: 0.7858\n",
      "Epoch 81/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 2.2118 - acc: 0.7719 - val_loss: 2.1626 - val_acc: 0.7817\n",
      "Epoch 82/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 1.9522 - acc: 0.7912 - val_loss: 2.0400 - val_acc: 0.8047\n",
      "Epoch 83/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 2.0998 - acc: 0.7756 - val_loss: 2.1412 - val_acc: 0.7768\n",
      "Epoch 84/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 1.8964 - acc: 0.7887 - val_loss: 2.0622 - val_acc: 0.7889\n",
      "Epoch 85/200\n",
      "50/50 [==============================] - 362s 7s/step - loss: 2.0781 - acc: 0.7713 - val_loss: 2.0055 - val_acc: 0.8003\n",
      "Epoch 86/200\n",
      "50/50 [==============================] - 359s 7s/step - loss: 1.9031 - acc: 0.7800 - val_loss: 2.0202 - val_acc: 0.7906\n",
      "Epoch 87/200\n",
      "50/50 [==============================] - 358s 7s/step - loss: 1.7950 - acc: 0.8025 - val_loss: 1.9680 - val_acc: 0.8003\n",
      "Epoch 88/200\n",
      "50/50 [==============================] - 358s 7s/step - loss: 1.7785 - acc: 0.7994 - val_loss: 1.9616 - val_acc: 0.7986\n",
      "Epoch 89/200\n",
      "50/50 [==============================] - 361s 7s/step - loss: 1.9178 - acc: 0.7962 - val_loss: 1.9171 - val_acc: 0.8053\n",
      "Epoch 90/200\n",
      "50/50 [==============================] - 358s 7s/step - loss: 1.9228 - acc: 0.8037 - val_loss: 1.9065 - val_acc: 0.8040\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.7449 - acc: 0.7981 - val_loss: 1.8255 - val_acc: 0.8177\n",
      "Epoch 92/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.7185 - acc: 0.8206 - val_loss: 1.8299 - val_acc: 0.8100\n",
      "Epoch 93/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.6345 - acc: 0.8131 - val_loss: 1.8163 - val_acc: 0.8122\n",
      "Epoch 94/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.6482 - acc: 0.8238 - val_loss: 1.7890 - val_acc: 0.8161\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.7961 - acc: 0.7975 - val_loss: 1.7791 - val_acc: 0.8156\n",
      "Epoch 96/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 1.7663 - acc: 0.8175 - val_loss: 1.7499 - val_acc: 0.8210\n",
      "Epoch 97/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 1.5623 - acc: 0.8206 - val_loss: 1.6864 - val_acc: 0.8338\n",
      "Epoch 98/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 1.5521 - acc: 0.8294 - val_loss: 1.6765 - val_acc: 0.8279\n",
      "Epoch 99/200\n",
      "50/50 [==============================] - 373s 8s/step - loss: 1.6010 - acc: 0.8106 - val_loss: 1.7041 - val_acc: 0.8224\n",
      "Epoch 100/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.5077 - acc: 0.8325 - val_loss: 1.6569 - val_acc: 0.8276\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.4332 - acc: 0.8394 - val_loss: 1.5960 - val_acc: 0.8379\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 1.5188 - acc: 0.8231 - val_loss: 1.5756 - val_acc: 0.8415\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - 369s 8s/step - loss: 1.3690 - acc: 0.8388 - val_loss: 1.5929 - val_acc: 0.8330\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.3440 - acc: 0.8438 - val_loss: 1.5442 - val_acc: 0.8444\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 370s 8s/step - loss: 1.3586 - acc: 0.8506 - val_loss: 1.5238 - val_acc: 0.8449\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 1.3727 - acc: 0.8438 - val_loss: 1.5672 - val_acc: 0.8342\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.3231 - acc: 0.8394 - val_loss: 1.5009 - val_acc: 0.8480\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - 370s 8s/step - loss: 1.2641 - acc: 0.8494 - val_loss: 1.5085 - val_acc: 0.8406\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - 370s 8s/step - loss: 1.3208 - acc: 0.8550 - val_loss: 1.5463 - val_acc: 0.8324\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - 372s 8s/step - loss: 1.3533 - acc: 0.8487 - val_loss: 1.4966 - val_acc: 0.8415\n",
      "Epoch 111/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 1.3035 - acc: 0.8338 - val_loss: 1.5318 - val_acc: 0.8342\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - 359s 7s/step - loss: 1.3830 - acc: 0.8363 - val_loss: 1.5676 - val_acc: 0.8267\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 357s 7s/step - loss: 1.5559 - acc: 0.8112 - val_loss: 1.5807 - val_acc: 0.8214\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - 357s 7s/step - loss: 1.5075 - acc: 0.8263 - val_loss: 1.5249 - val_acc: 0.8309\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 358s 7s/step - loss: 1.2818 - acc: 0.8331 - val_loss: 1.4107 - val_acc: 0.8541\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - 358s 7s/step - loss: 1.2573 - acc: 0.8544 - val_loss: 1.4142 - val_acc: 0.8512\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - 363s 7s/step - loss: 1.3491 - acc: 0.8388 - val_loss: 1.4620 - val_acc: 0.8419\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.2355 - acc: 0.8450 - val_loss: 1.3912 - val_acc: 0.8561\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - 369s 8s/step - loss: 1.2092 - acc: 0.8731 - val_loss: 1.4096 - val_acc: 0.8524\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 357s 7s/step - loss: 1.2228 - acc: 0.8675 - val_loss: 1.3726 - val_acc: 0.8564\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - 356s 7s/step - loss: 1.1510 - acc: 0.8700 - val_loss: 1.3484 - val_acc: 0.8588\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 355s 7s/step - loss: 1.5537 - acc: 0.8375 - val_loss: 1.5144 - val_acc: 0.8205\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - 356s 7s/step - loss: 1.2952 - acc: 0.8300 - val_loss: 1.3794 - val_acc: 0.8503\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - 355s 7s/step - loss: 1.1887 - acc: 0.8637 - val_loss: 1.3699 - val_acc: 0.8516\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - 356s 7s/step - loss: 1.1852 - acc: 0.8612 - val_loss: 1.3673 - val_acc: 0.8522\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - 355s 7s/step - loss: 1.1968 - acc: 0.8600 - val_loss: 1.2776 - val_acc: 0.8713\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - 355s 7s/step - loss: 1.2237 - acc: 0.8519 - val_loss: 1.3681 - val_acc: 0.8487\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - 356s 7s/step - loss: 1.2789 - acc: 0.8519 - val_loss: 1.3493 - val_acc: 0.8513\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - 359s 7s/step - loss: 1.1348 - acc: 0.8669 - val_loss: 1.3070 - val_acc: 0.8599\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 369s 8s/step - loss: 1.1824 - acc: 0.8606 - val_loss: 1.3339 - val_acc: 0.8558\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - 371s 8s/step - loss: 1.2491 - acc: 0.8656 - val_loss: 1.4209 - val_acc: 0.8352\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 370s 8s/step - loss: 1.3106 - acc: 0.8363 - val_loss: 1.3208 - val_acc: 0.8564\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - 369s 8s/step - loss: 1.1681 - acc: 0.8537 - val_loss: 1.2845 - val_acc: 0.8631\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - 369s 8s/step - loss: 1.0991 - acc: 0.8731 - val_loss: 1.2553 - val_acc: 0.8700\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 369s 8s/step - loss: 1.1395 - acc: 0.8863 - val_loss: 1.2576 - val_acc: 0.8678\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - 370s 8s/step - loss: 1.0967 - acc: 0.8719 - val_loss: 1.2389 - val_acc: 0.8680\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - 355s 7s/step - loss: 1.1714 - acc: 0.8694 - val_loss: 1.3336 - val_acc: 0.8493\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - 355s 7s/step - loss: 1.0488 - acc: 0.8700 - val_loss: 1.2676 - val_acc: 0.8621\n",
      "Epoch 139/200\n",
      "50/50 [==============================] - 355s 7s/step - loss: 1.1216 - acc: 0.8737 - val_loss: 1.2632 - val_acc: 0.8616\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - 355s 7s/step - loss: 1.2047 - acc: 0.8562 - val_loss: 1.2417 - val_acc: 0.8665\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - 354s 7s/step - loss: 1.1516 - acc: 0.8606 - val_loss: 1.2450 - val_acc: 0.8657\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - 356s 7s/step - loss: 1.0659 - acc: 0.8694 - val_loss: 1.2214 - val_acc: 0.8700\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - 369s 8s/step - loss: 0.9540 - acc: 0.8956 - val_loss: 1.1567 - val_acc: 0.8838\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - 368s 8s/step - loss: 1.0333 - acc: 0.8838 - val_loss: 1.1793 - val_acc: 0.8777\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 0.9597 - acc: 0.8925 - val_loss: 1.1669 - val_acc: 0.8766\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - 368s 8s/step - loss: 1.0056 - acc: 0.8919 - val_loss: 1.1802 - val_acc: 0.8762\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 1.0680 - acc: 0.8706 - val_loss: 1.1376 - val_acc: 0.8848\n",
      "Epoch 148/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 0.9596 - acc: 0.8963 - val_loss: 1.1674 - val_acc: 0.8747\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - 368s 7s/step - loss: 1.0000 - acc: 0.8850 - val_loss: 1.1315 - val_acc: 0.8852\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - 368s 7s/step - loss: 0.9547 - acc: 0.8963 - val_loss: 1.1077 - val_acc: 0.8888\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - 366s 7s/step - loss: 0.9447 - acc: 0.8888 - val_loss: 1.1350 - val_acc: 0.8798\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 0.9248 - acc: 0.9044 - val_loss: 1.0919 - val_acc: 0.8906\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - 368s 7s/step - loss: 0.9265 - acc: 0.9044 - val_loss: 1.0877 - val_acc: 0.8905\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - 366s 7s/step - loss: 0.9024 - acc: 0.9031 - val_loss: 1.0994 - val_acc: 0.8882\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 368s 8s/step - loss: 0.8965 - acc: 0.9000 - val_loss: 1.0667 - val_acc: 0.8942\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - 366s 7s/step - loss: 1.1346 - acc: 0.8650 - val_loss: 1.1768 - val_acc: 0.8698\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 1.0004 - acc: 0.8825 - val_loss: 1.1174 - val_acc: 0.8852\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - 366s 7s/step - loss: 1.0670 - acc: 0.8756 - val_loss: 1.2083 - val_acc: 0.8637\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - 366s 7s/step - loss: 1.1085 - acc: 0.8700 - val_loss: 1.1554 - val_acc: 0.8751\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 1.0408 - acc: 0.8906 - val_loss: 1.0941 - val_acc: 0.8873\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - 368s 7s/step - loss: 0.8577 - acc: 0.9156 - val_loss: 1.0834 - val_acc: 0.8888\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 0.9110 - acc: 0.8988 - val_loss: 1.0737 - val_acc: 0.8904\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - 366s 7s/step - loss: 0.8910 - acc: 0.9000 - val_loss: 1.0488 - val_acc: 0.8943\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 0.8250 - acc: 0.9094 - val_loss: 1.0337 - val_acc: 0.8975\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 0.9574 - acc: 0.8788 - val_loss: 1.0997 - val_acc: 0.8828\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 0.8718 - acc: 0.9044 - val_loss: 1.0274 - val_acc: 0.8976\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 1.0038 - acc: 0.8944 - val_loss: 1.0697 - val_acc: 0.8881\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 0.9507 - acc: 0.8900 - val_loss: 1.0647 - val_acc: 0.8920\n",
      "Epoch 169/200\n",
      "50/50 [==============================] - 364s 7s/step - loss: 0.8380 - acc: 0.9137 - val_loss: 1.0661 - val_acc: 0.8877\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - 354s 7s/step - loss: 0.8715 - acc: 0.8944 - val_loss: 1.0526 - val_acc: 0.8893\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - 355s 7s/step - loss: 0.8853 - acc: 0.8944 - val_loss: 1.0480 - val_acc: 0.8903\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - 354s 7s/step - loss: 0.9931 - acc: 0.8813 - val_loss: 1.0931 - val_acc: 0.8802\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - 354s 7s/step - loss: 0.8632 - acc: 0.9075 - val_loss: 1.0602 - val_acc: 0.8894\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - 353s 7s/step - loss: 0.9392 - acc: 0.9062 - val_loss: 1.1503 - val_acc: 0.8695\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - 359s 7s/step - loss: 1.0007 - acc: 0.8662 - val_loss: 1.0784 - val_acc: 0.8827\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - 361s 7s/step - loss: 1.0052 - acc: 0.8763 - val_loss: 1.0762 - val_acc: 0.8829\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - 353s 7s/step - loss: 0.8850 - acc: 0.8950 - val_loss: 1.0584 - val_acc: 0.8858\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - 353s 7s/step - loss: 0.9902 - acc: 0.8838 - val_loss: 1.0794 - val_acc: 0.8813\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - 354s 7s/step - loss: 0.8511 - acc: 0.8863 - val_loss: 1.0266 - val_acc: 0.8945\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - 352s 7s/step - loss: 0.8832 - acc: 0.9062 - val_loss: 1.0571 - val_acc: 0.8870\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - 351s 7s/step - loss: 1.1017 - acc: 0.8719 - val_loss: 1.1326 - val_acc: 0.8707\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - 352s 7s/step - loss: 0.9462 - acc: 0.8906 - val_loss: 1.0384 - val_acc: 0.8916\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 352s 7s/step - loss: 0.9086 - acc: 0.8950 - val_loss: 1.0585 - val_acc: 0.8859\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - 362s 7s/step - loss: 0.9801 - acc: 0.8750 - val_loss: 1.0386 - val_acc: 0.8895\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 0.8443 - acc: 0.9106 - val_loss: 1.0265 - val_acc: 0.8929\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 0.8815 - acc: 0.9112 - val_loss: 0.9967 - val_acc: 0.8990\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - 353s 7s/step - loss: 0.9195 - acc: 0.8794 - val_loss: 1.0127 - val_acc: 0.8949\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - 351s 7s/step - loss: 0.8255 - acc: 0.9137 - val_loss: 1.0032 - val_acc: 0.8947\n",
      "Epoch 189/200\n",
      "50/50 [==============================] - 352s 7s/step - loss: 0.8711 - acc: 0.8981 - val_loss: 1.0068 - val_acc: 0.8959\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - 351s 7s/step - loss: 0.8631 - acc: 0.9112 - val_loss: 0.9805 - val_acc: 0.8996\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - 352s 7s/step - loss: 0.8039 - acc: 0.9150 - val_loss: 0.9765 - val_acc: 0.9012\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - 352s 7s/step - loss: 0.8194 - acc: 0.9144 - val_loss: 1.0354 - val_acc: 0.8862\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - 363s 7s/step - loss: 0.8850 - acc: 0.8856 - val_loss: 1.0092 - val_acc: 0.8949\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - 364s 7s/step - loss: 0.7669 - acc: 0.9150 - val_loss: 0.9411 - val_acc: 0.9087\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - 365s 7s/step - loss: 0.7641 - acc: 0.9294 - val_loss: 0.9466 - val_acc: 0.9062\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 364s 7s/step - loss: 0.7965 - acc: 0.9156 - val_loss: 0.9768 - val_acc: 0.8975\n",
      "Epoch 197/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 0.8055 - acc: 0.9131 - val_loss: 0.9380 - val_acc: 0.9082\n",
      "Epoch 198/200\n",
      "50/50 [==============================] - 368s 8s/step - loss: 0.7046 - acc: 0.9275 - val_loss: 0.9005 - val_acc: 0.9146\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - 375s 8s/step - loss: 0.7391 - acc: 0.9231 - val_loss: 0.9204 - val_acc: 0.9106\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - 367s 7s/step - loss: 0.7834 - acc: 0.9112 - val_loss: 0.9276 - val_acc: 0.9079\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "base_model = keras.applications.InceptionResNetV2(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(152, 152, 3),\n",
    "    include_top=False)\n",
    "\n",
    "base_model.trainable = False\n",
    "    \n",
    "inputs = keras.Input(shape=(152, 152, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(4096, kernel_regularizer=keras.regularizers.l2(0.001), activation = 'relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(1595, activation = 'softmax')(x) \n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "train_class_weights = {key: value for (key, value) in enumerate(class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(train_generator.classes), \n",
    "                train_generator.classes))}\n",
    "\n",
    "#print(train_class_weights)\n",
    "\n",
    "validation_class_weights = {key: value for (key, value) in enumerate(class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(validation_generator.classes), \n",
    "                validation_generator.classes))}\n",
    "\n",
    "#print(validation_class_weights)\n",
    "\n",
    "#from_logits=True\n",
    "#loss=keras.losses.CategoricalCrossentropy(),\n",
    "#optimizer=keras.optimizers.RMSprop(),\n",
    "#metrics=[keras.metrics.CategoricalAccuracy()]\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "training_history = model.fit(train_generator, \n",
    "                             steps_per_epoch=50,\n",
    "                             epochs=200, \n",
    "                             batch_size=32, \n",
    "                             class_weight=train_class_weights, \n",
    "                             validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97cc721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def printplt(history):\n",
    "  loss = history.history['loss']\n",
    "  epochs = range(1, len(loss) + 1)\n",
    "  accuracy = history.history['acc']\n",
    "  val_accuracy = history.history['val_acc']\n",
    "\n",
    "  plt.plot(epochs, accuracy, 'r', label='Training accuracy')\n",
    "  plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "  plt.title('Training and validation accuracy')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea824132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABFBUlEQVR4nO3dd3gU5fbA8e9JIIQmJYB0QUEURVpEqYpYQBEEFQRRsIMVy0WvchXFxrVXFEX6T8pVqhQBAUVAE0IRAWlSEnqvCSnn98c7CUtIYIPZbEjO53nyZHdmdvbsZDNn3jLvK6qKMcaY/Csk2AEYY4wJLksExhiTz1kiMMaYfM4SgTHG5HOWCIwxJp+zRGCMMfmcJQJzChGZJiLds3vbYBKRjSJyfQD2qyJSw3v8hYj8x59tz+J97haRH882TmNOR+w+grxBRA77PC0CJADJ3vNHVHVUzkeVe4jIRuBBVZ2VzftVoKaqrsuubUWkGvA3UFBVk7IlUGNOo0CwAzDZQ1WLpT4+3UlPRArYycXkFvZ9zB2saiiPE5FrRSRWRJ4Xke3AEBEpJSJTRGSXiOzzHlf2ec1cEXnQe9xDROaLyLvetn+LSJuz3La6iPwsIodEZJaIfCYiIzOJ258Y+4vIr97+fhSRMj7r7xGRTSKyR0ReOs3xuUpEtotIqM+yDiKy3HvcSEQWish+EdkmIp+KSFgm+xoqIq/7PP+X95qtInJ/um1vEZElInJQRLaISD+f1T97v/eLyGERaZx6bH1e30REokTkgPe7ib/HJovHubSIDPE+wz4RmeCzrr2ILPU+w3oRae0tP6kaTkT6pf6dRaSaV0X2gIhsBn7ylo/z/g4HvO/IZT6vLywi73l/zwPed6ywiPwgIk+k+zzLRaRDRp/VZM4SQf5QHigNXAA8jPu7D/GeVwWOAZ+e5vVXAX8BZYD/AoNFRM5i2/8DfgcigH7APad5T39i7ArcB5QDwoDnAESkNjDQ239F7/0qkwFV/Q04AlyXbr//5z1OBp72Pk9joBXw6GnixouhtRfPDUBNIH37xBHgXqAkcAvQS0Ru89a18H6XVNViqrow3b5LAz8AH3uf7X3gBxGJSPcZTjk2GTjTcR6Bq2q8zNvXB14MjYDhwL+8z9AC2JjJe2TkGuBS4Cbv+TTccSoHxAC+VZnvAg2BJrjvcR8gBRgGdEvdSETqApVwx8ZkharaTx77wf1DXu89vhY4DoSfZvt6wD6f53NxVUsAPYB1PuuKAAqUz8q2uJNMElDEZ/1IYKSfnymjGPv6PH8UmO49fhkY7bOuqHcMrs9k368D33iPi+NO0hdksm1vYLzPcwVqeI+HAq97j78B3vbZ7mLfbTPY74fAB97jat62BXzW9wDme4/vAX5P9/qFQI8zHZusHGegAu6EWyqD7b5Mjfd03z/veb/Uv7PPZ7vwNDGU9LYpgUtUx4C6GWwXDuzDtbuASxifB+J/Kq//WIkgf9ilqvGpT0SkiIh86RW1D+KqIkr6Vo+ksz31gaoe9R4Wy+K2FYG9PssAtmQWsJ8xbvd5fNQnpoq++1bVI8CezN4Ld/XfUUQKAR2BGFXd5MVxsVddst2L401c6eBMTooB2JTu810lInO8KpkDQE8/95u6703plm3CXQ2nyuzYnOQMx7kK7m+2L4OXVgHW+xlvRtKOjYiEisjbXvXSQU6ULMp4P+EZvZf3nR4DdBOREKALrgRjssgSQf6QvmvYs0At4CpVPY8TVRGZVfdkh21AaREp4rOsymm2/ycxbvPdt/eeEZltrKorcSfSNpxcLQSuimk17qrzPODFs4kBVyLy9X/AJKCKqpYAvvDZ75m68m3FVeX4qgrE+RFXeqc7zltwf7OSGbxuC3BRJvs8gisNpiqfwTa+n7Er0B5XfVYCV2pIjWE3EH+a9xoG3I2rsjuq6arRjH8sEeRPxXHF7f1effMrgX5D7wo7GugnImEi0hi4NUAx/g9oKyLNvIbd1zjzd/3/gKdwJ8Jx6eI4CBwWkUuAXn7GMBboISK1vUSUPv7iuKvteK++vavPul24KpkLM9n3VOBiEekqIgVEpDNQG5jiZ2zp48jwOKvqNlzd/edeo3JBEUlNFIOB+0SklYiEiEgl7/gALAXu8raPBO7wI4YEXKmtCK7UlRpDCq6a7X0RqeiVHhp7pTe8E38K8B5WGjhrlgjypw+BwrirrUXA9Bx637txDa57cPXyY3AngIx8yFnGqKp/Ao/hTu7bcPXIsWd42be4BsyfVHW3z/LncCfpQ8BXXsz+xDDN+ww/Aeu8374eBV4TkUO4No2xPq89CrwB/Cqut9LV6fa9B2iLu5rfg2s8bZsubn99yOmP8z1AIq5UtBPXRoKq/o5rjP4AOADM40Qp5T+4K/h9wKucXMLKyHBciSwOWOnF4es54A8gCtgLDODkc9dwoA6uzcmcBbuhzASNiIwBVqtqwEskJu8SkXuBh1W1WbBjOVdZicDkGBG5UkQu8qoSWuPqhScEOSxzDvOq3R4FBgU7lnOZJQKTk8rjujYexvWB76WqS4IakTlnichNuPaUHZy5+smchlUNGWNMPmclAmOMyefOuUHnypQpo9WqVQt2GMYYc05ZvHjxblUtm9G6cy4RVKtWjejo6GCHYYwx5xQRSX83ehqrGjLGmHzOEoExxuRzlgiMMSafs0RgjDH5nCUCY4zJ5ywRGGNMPmeJwBhj8jlLBMYYkxvMnw8//3zysoTMRmnPXpYIjDEm2I4cgQ4d4Lbb4MABt2zFCihZEjp2hC2ZzuqaLSwRGGNMsH3xBezeDfv2wQcfuGX9+0NICEyfDo0bw6FDAXt7SwTGmHPTvHkwe7b/26ekwOHDgYsns/f0PYGrwsyZMGIELFjglh09Cv/9L1x/Pdx+O7z/Pgwbho4dx88dP+TIlDkQFwevvRa4OFX1nPpp2LChGmOMXnSRapkyqseOnVgWF6eakpLx9m+9pRoRoXrwYOBiGjVK9bnnVN97zz3/+mvV4sVdXBs3qjZurOrSgftZulR17FhNRlRnz1ZduVK1VClNJFQfKvCNgmrFiqpfNh2mh0JLqP7551mHBkRrJudVKxEYY4IrJcXVgW/a5H/j6Nq1sH69q04ZN84tmzgRKleG8ePd8yNHTn7NmDGwZ8+J9amWLYNWreChh2Dx4tO/b1RU5qWQ7dvh7rvhvffg2Wdhxw637aFD8Mkn0Ls3LF8OgwbBIm9a5tmzmft/Wwknnuv6X8uPWy6F2Fh6tlzDV0n38eij7iM98uu9VEiJZfiHe/07PlmVWYbIrT9WIjAmj3n55RNXyAUKqDZooPrll6rx8Zm/5uOP3fbly6teeaW7Ui5Rwi3r1Ut1+3bVwoVdKUBVdfPmE+/RqtXJ+3rySfe+4eGqbdtm/p4pKaq1a6tWrpzx+smT3f4HDHC/x49XrVHDPS5cWFNA1/b+VEeNUl2zRlVr1NCUW9vpVUWWabmwvVqtmmpYmOorr7iXvPDCibedP1+1R7dE/e03/w5pRjhNiSDoJ/as/lgiMCaXSklRXbcu8/Vxca4qRFV1927VqCjVQ4dUS5ZUbdnSVaO8+KJqvXru1PT885nvq00b1Zo1VT/5JO0Ev6hYK3227FCNu7SVHh88XF/lP7o65FLV335T/fxzt12nTqoiqlu2nNjXpZeq3nSTapcuqlWrnvw+vtVOS5acSCbbtp1Yfvy4+92vnyYRqr0fOaoXsk5HtvxK91FCt7XuodO5UVuG/ZL28vr1VVPuf0AnF75TQfWr9pN1925X2wWqdeqoJiT4ddT9ZonAGBN4M2a4U8ro0e4E//rrqv37qy5Y4Nbfdpu7Sl+3TvXqq90J+dZbNQV0/XdLdO1ad079e0OKtiwRrV9X75/x+xw96q7en3xSUw4f0d+6f6Yta25OO8nez2AdWvc9BdWLC6zT3eUv0/9VfVrXVbnWvTdoYoFwPXLZlarLlrkXvfuu6ptvusf797v3+fln1YIFVX/8UZctU73gvD36LZ3dNpMm6fa/j+rSBz5224wapauu7amti85TUK1WKO6kpgBQLVsiXt95xx0SUB37+DytxSq9kHV6fPbPquoKNtdffyJfZidLBMaYrDt+3F3F++uJJzStdfPWW0+cAc8/311ZFyumCrq3XC19if76ULFRmkioPllhbNqmERHuB1TryZITV9s+4idM0/fpre2v3q7nn++dZMuqfvCB6oNtYrUAx7UqG7VKkV0aEpKi4XJMQTUsJFFvv121dsW9WjAkUYtxUFdXvUGncLPecPVB3T9mutvZ/Pnujbp00XjCVKtX15taJbqaK0nUKdJW9T//0bZVlqiQrP8u8F+9q+wsFZK1SOgx/fxz1eSnntb/0VHfp7d+MuCIzpjhcqOqu9KvXFk1JCRFQ0nUnwrccHLJI0AsERhjsu7RR1WLFlXdutWvzXfUaKJPlBiq66nuTi0ffKA6Zoyu5mJtUmWzzuEa/bv5PVqGnWkn/purLFdQ7dZN9ZtvVLt2dVX4D7Zcp6AaO2OFXtfooP7niX1p7/NSnYkKqjVrJOs997hanwMH3LrNqw5rQRIUVMc9MU8/+EC1aZNkHffEPO125zGtWFH1lltcrVPpQoe0Dsv0PDmgoPr1gN16jEL6RZe5+tqLR/VqWeRiZIqC6iu8ovWr79VyBXbr1oZttQDHtWKRfQqqxTioL/Cm7nxtoAtkzBj3AWvWzPBYpTZxfFKmn2rz5mf/N8oCSwTGmKxZvVo1NNSdIp5++szbb9miPfncXZ0XPazftv9WV69K0Q0rjmhNWaOgWoE4bXpVohYPT9Do6Tv1scfc7mvUUD1y5OTdLZ+ySUH19ivca8vKTk1cGKVr/ojXMOK120ULMg3l6XIjtBGLNHnbjtOG/N0XLiGVDjukVauqtmyZov8K+zAtSV3CSu3RdpeGSrJWLbxDj438n86amaKgeg1zFFSjh63Q2SPidDel3YvmzXM7T22c7to1w/dOSVFdtUo1Zekyr+U48CwRGJMXRUWd3GiZnTp0cFU5t97q6vW3bz+xbvly1UGDVJOT0xZtGDBWC3BcO7ban9ZRJvUnLOS4fk5PLSjHFVQHD3avSUhwV+YxMae+fUpyilYRV+8fQpKC6uwibfWmqiv1PPbrttFzM4/9889Vu3f362N+02+TRv24V/v1c00WhSRe74n4QRMurat6+eWqKSm6Zo3q3397caWoXl5xt4LqRWGbNCXZu2chtc3D9x6Fp55SnTPHrzhygiUCY/Ka/ftdI2W5cqoDB6o+8IDqrFkZbrpkiWqVKukuPFNSMr3xan/Men2Cj/Sl5vN0+tdb9Ee5UQ+df5Grv7nxRnfCA9Xp01VVdd8+1bYVojWcoxoXm6LHjqkuXKg6fLjqp5+qLnx9liroqDu+1xdeyPx+r/R6VpqkoPpquU+1cHiyXha+VkH1w2IvqSYm+n+s/LB2rftIhUKP6yaquCeTJ2e47dcvu9LKi60WnVj400+uFTgXs0RgTF4zZYqmta6mXnrfeuuJ9YmJqlOnqu7bpw895Fa/+qrP6x94QLVuXXcGfOONtJW7d6tGVozVUBI1JCQlbdePVf9BtWJFTalzhaY8/4IuKdVSG5X6SytUUC1VLEGFZH2n6fiMY42PV+3TJ8ull8XdP9K2TNID73ypd9zh4qhTJk4Tv/g6S/vx1333qQ7osNC90aOPZrpdfLzqS1036LbNpzZk52aWCIzJa5591t19tHOnJs9foNGtX9L9EReeuNwePlwV9GjB8/S80EOuF06dJLdu1SqdyzU6lHs1SQpo6o1c29Yf0csvT9FCxOvken11925X5d2unevqv2+fu58qLEw1RJK1PFv1vhZr9e4Co3XxJV1dt87sFBXl+lIeOKATJ7omi59/zt63OMXu3e7KPn2jRR5gicCY3GjvXlfXfvjwaTdbtkx1/4Y97oG63o0Pl/lOYxo8oO++q1qpknfVzieq69e7F/XqpVq8uH578zCv58sPCqob/jquMe1e0cIcUVCtW3ydxnZ/UY8SrrWqHNYi4Uk6i+tUR4xIe/9ZrmZHmzVzvx95RPWlR/eeaCCtWdM1jgbY3r0Bf4s8zRKBMcG0aZPqRx+dPGTCH3+cuI00MvLkxlgfa9a4Kvkiocf0X6HvadLWHXr5pUknNcbecINqrWrHtBGLVEeN0mnTVB8q8502K7FcIyLczbJr3vqfgmqXYhO1Mpu1crG9Oniwu8r+9zPH9Du53Y2KcN3HrsuoT3JKTla94AL3Xjff7BNc//7uJwf6wJt/zhKBMUGyc9F6/alsJ42hnurNN+vcH+O1Vo1EnV+qrRsnZ8AA1yunSZMMW1Hfecf9l3YIdX3n29T4S0H1Ux7V9x5dpzNmuO2efipZC3NEjz/6lJYqlaLnsV9bVFmvd96pOmmS2+aKyq63S7WiO3Tx9J2q6kZWqF5dtVPJGVqmwF5NDC+m+tBDp8TRv78bjmfFioAdKhNglgiMySG74+L1rbdcLc624T9qadmTduU+kXbasPCfCqrFOaC//99aVVWd+tgUnURb1/MknebNVetV36cpoLcVnub6txdcp0nnlTrpSnzoUPce4y56XkF1GPeofv/9Sftat071119P6vWpQ4a414VIsj7CQPckOvqUOI4fP9GF0pybLBEYE2jx8fr91QO0mLiG2fNLHNU2/KBhkqATPt2ideqoFg5zwxS8zotaPWK/linjquILFEhRIVlH1H5Tddo01d9/V1XVXbtUQ0JUX778O9WICN036Wdtz3idVfw2d0b3kToeWgvcWDcbqKYaG3vGsPftc42/oK5t4MorA3BwTG5gicCYbPTmm6rXXeeq/lVVNSVFN19/n5ZgnzYkSifcN0HPCznoumz+x/V3j4529fEX10jSxCnT9a/VKVraa2u96CLVlhdu1BCSdBy3u7F6UlJ02DDvAr1wM1ddk5LiJj7JYITPhATVggWSFVQrsUVTKlT0+/N07Kha/vxkTSxV1g2NYPIkSwTGZJN169x9XKBaNnSP/vxBtB75OVpbMluLhiXougZ3qoaH6xyu0YdbrTupfXjmTDesQKpff3VVP8uWqR7aflibVN6oBUKSdCK36rHflmnd2glapUCcphQp6tdwlFdc4eLqLKPdncF+2rvXTZ7l951e5pxkicCYrEqtSI+Lc+PUe6NwduqkWqRIis6u0l0vZrUWkES9sKRrhP3m40Oq48a5f6tq1bJ89+v+/aqRdd3NWQ0rbVVQ/aHw7SeGcT6De+91b/3psxusQt+c4nSJwKaqNMbH4sWwcvRyKF0aRo2Chx7i4LdTODLsf/R9SRk7Fp4r+DHXbRvFbzf8hzY6lWMHE/mxwQvc90QxuO02aNMG3noLChTI0nuXKAFz5odxT6kfWBxXged5m5v7NYLGjf16ff367neL7tWhWrWsfXCTr4lLFOeOyMhIjY6ODnYYJg/atw+qV4fko/HMSWxGcQ7xOn0ZyT1p2zzA13zWaDiF+veFGjXgootIQQj58gt4+OHsCeSFF/hrwHguLrET2bwJzjvPr5cdPgwzZ0KHDtkThslbRGSxqkZmtC5rlyxZf+PWwEdAKPC1qr6dbn1VYBhQ0tvmBVWdGsiYjMnMu+/CgQNQKWQfjWURSVqA8JAEnq7zE2X/nMuljUty29J+MHcHFC7sXnTNNYT88osrCWSXm2+m1oAB8ERfv5MAQLFilgTM2QlYIhCRUOAz4AYgFogSkUmqutJns77AWFUdKCK1galAtUDFZPKPhQshOhqeeCKTDQ4cgEKFSJBw/vUviP07kR9nwl2t9tN/dnNebTKDRp0v5Pbbw6gYcwTa9YdfgO7dTyQBgA8/hGXLoFy57Au+eXMYOxZuuSX79mnMaQSyRNAIWKeqGwBEZDTQHvBNBAqkXvKUALYGMB6Tj7z8MsyeDd26QalSkJIC/frBjTdC06uSeKnKCI4mFuSP8jfw08YLuTB8J2EJhXl14Y3UCN3IiMmloLS4nZ13ravvT0qCu+8++Y3q1XM/2UkE7rwze/dpzGkEsrG4ErDF53mst8xXP6CbiMTiSgMZXr+JyMMiEi0i0bt27QpErCYP2b8f5s519/P+/LNbNmwY9O/vanBe7B7HW4ceZ2DCfczbWJWhdGf98arsffp1LmYNXH+9ayxOVbw4NG0K5cvDddcF4RMZE1jB7jXUBRiqqpWBm4ERInJKTKo6SFUjVTWybNmyOR6kObdMm+Yu3gHmzIF9OxPp81wydetCfDy8/e0FtAuZzKE9ieyO3kT3Z8rAt9/C++/D+vXucXqDB8OMGRAamrMfxpgcEMiqoTigis/zyt4yXw8ArQFUdaGIhANlgJ0BjMvkIQkJcPy4u2iPinI/M2fC+QV2UztpOXOmXMXxWYvZu7cps8YfYN3O8xjY7Ve+aTmGsFK3EtbwImj43okdli+f8RtddFHOfCBjgiCQiSAKqCki1XEJ4C6ga7ptNgOtgKEicikQDljdj/HLqlWuPTUiwiWAZ56B+fPdugcZTzU20nf9dfxBM57kY+ouEeo2a8btCc2h85DgBm9MLhKwRKCqSSLyODAD1zX0G1X9U0Rew93hNgl4FvhKRJ7GNRz30HPtxgaTM3btgoIFoWRJAH7/HW66CQ4ehL//dr2EFixw3ScTl6/ksY1fcqztnTARzpedvHrpWPhiH0ydCmFhcOutwf08xuQidkOZyfV+/x2WdXyV1YXqsrXRbdSu7arzS5d2jcDNm0Pduq4X528Lkml0R1Vo2JDEz7+ibbUVPNZ1H+1aHYEePdwOv/oKHnwwqJ/JmJwWtBvKjPmnvv0WunYFeIVwjlH2uDJ6tFClYhKzaz5OtU3NadSoK7//LpQrB5EHf4KtW+GjjyhY+XxmHCgGRYq4VuI33nAlAUsCxpwk2L2GjAHgyBH45ZdTl3/yCdQqs4cNVOcIRdk89Ce2bk5izQU3Um3Gl9CtGx3jPgVce0HIyOGu+qhtW7eDokVdv/zChWH1anjvvVPfxJh8zhKByRWefBJatIA+fVz/f4A//3R1/w8XHkH1y4sRUrAAzJxJhUGvEr5wDowcCSNH0unIEIpymK7lZsH330OnThAefuqbhNjX3ZiMWNWQCRpVOHoU4uJcXX+1aso77wgF/1zKGz/U46uvICxMuXfL69DrWZg+HYYOhZ074b770u7yrX7ddRzscCMhAxa6Hd97b/A+lDHnILtEMgGXkADbt5+6/Nln3fAPN98MhQrBoj7juY9veHtqHT66ayFffAG3X76GMuxx3YFuuAF27ICLL3Z1RqkqVCBk5gxo2dKNxdykSc59OGPyAEsEJuCeegoqVICaNd14/+C6en74IdSp49p2+zx9nPPffIoP6g6jQqF99B7TmGoVE/g4pLfrEnTJJa7Kp149GDPG1f37Kl4cfvrJdTESyeFPaMy5zRKBCYhVq9xNXuDG/bnsMjfg50svuQ48DzwAVarAvHlu+cslP4HYWEp83J/h3xbkupC5TC9/H2Wip8Ndd7kdXXwxLFniEkNmsjgZjDHG2ghMgPTo4er+V6yAv/6C1193y/v2dSM5r14N0yfEU2ztKndi/2Kgay1u0YLrgOuemAAfeWP+pCYCY0xAWInAZLu4OFdDExcHI0a4ZVc2TKFnga8pXNhN93jvvXDT2AegYUP497/dYG89e57YybPPujuJr77apl00JsCsRGCy3aRJJx7/97/ud2T8fEq/8BBPNq7Jt3HX8P4Tf8NVo12Xzv/+F8qUgY4dT7ywShXXFlC1as4Gb0w+ZCUCk+0mTnTT+V58McTGukbi0pOHAfDWoSdYuxYivh7g6vNnznSztj/+uOs65KtDB1diMMYElJUITLbat8913nnySTc89Jo1cGWDZPjuOyhaFFnxB2GLfnb3A/To4bp8xsW5YSCMMUFhJQJzVmJiXHf91atPLNu9240ImpKidNn7GTfuGwNAoyIrXNegt992G3bo4KqE+vZ1z1OHgTDGBIUlAnNW3n/fDf9w++1w+DBs3gzNmsEffyjfV36KhkMe58ZR3en72F66rnvNTfjSs6erJ9q7F/71L9cOYIwJOksEJssOHHBD+jRu7EoEl1wCkZHu7uEZN39Mu9jP4ZtvCCuo9P+9NWV/+R6ef961CXTr5mb76tMn2B/DGOOxRGCybOxYOHYMPvrIPW7WzLXpzhu5hRaT/+XuFrvvPnfSj4py3T979XIvfvll13CQ/s5gY0zQ2MQ0xm9JSfD1166qv2hRd7NYWtW+qqsnmjED1q1zY0qsWuUyxPDhcMcdQY3dmPzOJqYx2WLAANe+W7s2fPxxuvbdgQNh/Hi3UYUKbtmll7p6pIIFgxKvMcY/lgiMXxIT4bPP4MYb3WjQaUmgc2c3D/CxY24Y0eeeO/mFlgSMyfWsjcBkKDERLrzwxGjP330H27a5kUTTksDx4+7usdq13Y0Dw4fb5C/GnIPsv9ZkKCoK/v7b3fcFLiHUqAGtW/tstGSJm2ygTx/XnzQiIhihGmP+IUsEJkOzZ7vfMTGu6n/BAnjssXQX/Au9GcEaN87x+Iwx2ccSgcnQ7NnuHjCA++93vYTua77O1Q3t2uVWLFjgBoWrWDF4gRpj/jFLBOYUR4+6i/1u3VzHn/37ofu9Sok+j7juQo0aub6jCxdaacCYPMASgTnF/PmuHbhVKzcsEMDj9X91o8n17OnaBa6+2g0tavMDG3POs0RgiI+Hzz93s4ipumkAwsKg+Y//4d/XLmTRQuXSL56C6tXdRMO//+7GmAZ3W7Ex5pxm9xHkc3PmuKkjt2xxz48ccT2FnrzvEEU/eB2WzOeqd991rcYDB7o5AypXdsWGmBho0CCo8Rtj/jkrEeRjAwe66p/Chd38MM2bu+EjiheHvk1+chvNnQuvveaKCJ07n3hxkSJWGjAmj7ASQT6jCikp7haAJ5+ENm1cVVCxYu4GsiZN3DASESvmuZN/YqKbe/KOO6BUqWCHb4wJAEsE+cydd8KMGUqhkEQqlC/IyJFCsWJu3YUXusnCQkOBxgtd76DU4sK99wY1bmNM4FgiyEemT3dDRVxXZxcH/tjMh9f8RKlSJ88LEBqK6xUUE+PuGbjlFjjvvHS3FBtj8hJLBPlEfDw8/TTUqKFMK9iesJDfYXIK/FjPjSTnKybG9R9t3Biuucb9GGPyLGsszgfWrnXd/levhg97LCUsZpHrBnrJJfDww27k0FdfdbcSd+hwYhIZu1nMmHzBSgT5wAMPuDmFJ0+GWwa94uYLePhhqFMHWraERx+FkSPdKKJ//AGlS7sW49QxJowxeVpAE4GItAY+AkKBr1X17Qy26QT0AxRYpqpdAxlTfpOQAL/95qr727Y6Bp1mwUMPufsBrr0WbrvN3ThQsiTMmgVlywY3YGNMjgtYIhCRUOAz4AYgFogSkUmqutJnm5rAv4GmqrpPRMoFKp785tdfXZfQo0dPVPczd+6JCWRSvfOOGzPozTctCRiTTwWyRNAIWKeqGwBEZDTQHljps81DwGequg9AVXcGMJ58IyXFTR8cEeFGDgUvEbz+g7sRzLfxt0YNnz6jxpj8KJCNxZWALT7PY71lvi4GLhaRX0VkkVeVdAoReVhEokUkelfqEMgmU4sXw44dsHIlDBoE1apB+fMVfvjB3UocHn7yCywJGJOvBbvXUAGgJnAt0AX4SkRKpt9IVQepaqSqRpa16oszmjLFTSBTqBCsWeOVBtasgY0bT64WMsYYApsI4oAqPs8re8t8xQKTVDVRVf8G1uASg8mihAQYMsS1DUyZ4k7+HTu6dY0bA7/84p5cd13QYjTG5E6BTARRQE0RqS4iYcBdwKR020zAlQYQkTK4qqINAYwpT1q1ylX1338/tGjh7gdr29bdDlCoEFx/Pa5BOCICalqeNcacLGCJQFWTgMeBGcAqYKyq/ikir4lIO2+zGcAeEVkJzAH+pap7AhVTXjVsmGsTmDzZlQIKFoTbDo+k+fZxHDrkZhlj4UJ3V5lIsMM1xuQyoqrBjiFLIiMjNTo6Othh5CotWrguoosWudFF9y9cRanml7u5hDdtggMH3E1ir78OL70U7HCNMUEgIotVNTKjdcFuLDb/UGIiREWdGA1CBEq9/bzrQxobCz//7O4oAxsywhiTIUsE57ilS92AcmlTB//+u6sj6tvX3VE2ahQsWOC6ETVqFMxQjTG5lF83lInI98BgYJqqpgQ2JOOPLVvg++8hKck9T7vYnzHDFQuefdZVC40e7e4buOIK0iYeMMYYH/6WCD4HugJrReRtEakVwJiMH158EXr3dhf+Vau6aYQBVw10ySVu7KAHH3STENerB4MHBy9YY0yu5leJQFVnAbNEpATuxq9ZIrIF+AoYqaqJAYzRpHPggJtgpnp1+Ptvn9KAqksEbdu65y1auERQuHDQYjXG5H5+jzUkIhFAN+AeYAkwCmgGdMe7F8DkjDFj3Nhxo0e72p8GDbwVf/8Nu3fDVVed2NiSgDHmDPxtIxgP1AJGALeq6jZv1RgRsb6cOUgVvvkGLrsMrrwSGjVIcg3BhLiGYjg5ERhjzBn4WyL4WFXnZLQis36pJjD+7/9c7c+nn4IkxLvJZJKSoFs3N4po4cJuwhljjPGTv43FtX0HgxORUiLyaGBCMpnZuhUef9y1CfTsCXz1lasOql4dBgyA4cOhYUMoYBPPGWP8528ieEhV96c+8eYPeCggEZlMffyxa/sdOhRCE+Ph7beheXM34czKlW6woaeeCnaYxphzjL+XjqEiIuqNR+HNPhYWuLBMRqKjoW5duPhiYOhoV0QYPtzdN1CrlnURNcacFX9LBNNxDcOtRKQV8K23zOQQVTeqaFoPod9/d/cK2LDSxph/yN8SwfPAI0Av7/lM4OuARGQytHkz7NsH9et7C1audMOK2miixph/yN8bylKAgd6PCYKYGPc7rUSwahXcemvQ4jHG5B1+VQ2JSE0R+Z+IrBSRDak/gQ4uP0tOhtdeg2XL3POYGDe1cJ06wJ49sHOnN9GAMcb8M/62EQzBlQaSgJbAcGBkoIIyrmH4lVfgmmvcfQMxMe6WgcKFcaUBcAuMMeYf8jcRFFbV2biJbDapaj/glsCFZRYudL/POw+aNYPZs32qhVaudL+tRGCMyQb+JoIEEQnBjT76uIh0AGxM4wBauBCqVHGTzjz6qKsWuvFGb+XKlVCkiBt21Bhj/iF/E8FTQBHgSaAhbvC57oEKyrhE0LgxnH8+fPSRu5Gsa1dv5apVbqjpEJtXyBjzz53xTOLdPNZZVQ+raqyq3qeqt6vqohyIL1+Ki3MTz2Q6s2Rq11FjjMkGZ0wEqpqMG27a5JDU9oEME8Fff7m5iCNtrD9jTPbw94ayJSIyCRgHHEldqKrfBySqfG7BAihUyOfmMV8jRrgqoc6dczwuY0ze5G8iCAf2AL7jGShgiSCbpaS42cdatoSw9KM5paS4RHDDDVChQlDiM8bkPf7eWXxfoAMxzty5bjiJAQMyWPnzz27lW2/ldFjGmDzM3xnKhuBKACdR1fuzPaJ8buhQKFEC2rdPt+LAAXjiCShVCm67LQiRGWPyKn+rhqb4PA4HOgBbsz+c/GvHDjcX8f/+B/fem26q4ZQUuOMOWL0apk1z9xAYY0w28bdq6Dvf5yLyLTA/IBHlUw8/DJMmuV6hzzyDG3f6xx/h6qthyhSYNQsGDoTrrw92qMaYPOZs5zSsCZTLzkDyu8WLoUsXNycxABMmQocObob6XbtcF6KHHw5qjMaYvMnfNoJDnNxGsB03R4HJBnv3upvI0rqLJiTAc89BpUqwZImbnH7QILuT2BgTEP5WDRUPdCD52R9/uN916ngL3n8f1q+H6dPh+HE3FvUNNwQtPmNM3uZviaAD8JOqHvCelwSuVdUJgQst/1i+3P2+4gpg4kTo29c1Dt90k1thE9AYYwLI37qGV1KTAICq7gdeCUhE+dDy5RARARVS4lxDQWQkDBsW7LCMMfmEv4kgo+3OtqHZpPPHH65aSCaMh2PHXBKwLqLGmBzibyKIFpH3ReQi7+d9YHEgA8svUlJcIkirFqpVyw0xbYwxOcTfRPAEcBwYA4wG4oHHzvQiEWktIn+JyDoReeE0290uIioi+W5IzQUL4OhRuKLGUTe+xCm3FBtjTGD522voCJDpiTwj3jwGnwE3ALFAlIhMUtWV6bYrjpv45res7D8vGDIEevWC8uWhdehM1020Xbtgh2WMyWf8KhGIyEyvp1Dq81IiMuMML2sErFPVDap6HFeSyOhytz8wAFfKyDfmzYMHH4TmzWH5/62g0sC+ULasu5PYGGNykL9VQ2W8nkIAqOo+znxncSVgi8/zWG9ZGhFpAFRR1R9OtyMReVhEokUketeuXX6GnHvt2uWmE6hZE77773rK3tTADTb09dducmJjjMlB/vb8SRGRqqq6GUBEqpHBaKRZISIhwPtAjzNtq6qDgEEAkZGR/+h9c4NJk9x5f9IkOC/6J0hMdEUEm37SGBME/iaCl4D5IjIPEKA5cKaBb+KAKj7PK3vLUhUHLgfmighAeWCSiLRT1Wg/4zonLVzoRpOOjASGxLhxp62nkDEmSPxtLJ7u9eh5GFgCTACOneFlUUBNEamOSwB3AV199nkAKJP6XETmAs/l9SQALhFcfbU3dFBMjBtkyCVDY4zJcf42Fj8IzAaeBZ4DRgD9TvcaVU0CHgdmAKuAsar6p4i8JiL5tmvM/v2wcqU3MX1iohtHqEGDYIdljMnH/K0aegq4Elikqi1F5BLgzTO9SFWnAlPTLXs5k22v9TOWc9pvXifZxo2BVavcSKMNGwY1JmNM/uZvr6F4VY0HEJFCqroaqBW4sPKuhQtdLVCjRrhqIbASgTEmqPwtEcR69xFMAGaKyD5gU6CCyssWLoTLL4fzzsMlgqJFXT9SY4wJEn8bizt4D/uJyBygBDA9YFHlUaoQHe0mHgNg0SKoV8/uHTDGBFWWp7xS1XmqOsm7W9hkwebNbjayhg1xNxJERZ2Yc8AYY4LE5j7MQSc1CUz12tBt0hljTJBZIshBMTGuFuiKK4DJk6FyZahbN9hhGWPyOUsEOWjJEjeKROGQBPjxR2jb1m4kM8YEnSWCHBQT41ULzZ8PR47ALbcEOyRjjLFEkFO2bXM/DRrgZqMRcWNQG2NMkFkiCKA//oBOndw0xIu9iT3r18d1G61d2w02Z4wxQWaJIIDGj4dx41xzwIwZULgwXBmpLhHYBDTGmFzC3zuLzVn46y/3e+JE+OknuOEGKBy3zt1MYInAGJNLWIkggFavdr+//RY2bfJuGVi0yC286qqgxWWMMb6sRBAgqrBmDVSqBHHedDy3jOwCiZuhWDHXRmCMMbmAlQgCZOtWOHwYHnsMCoQkE0kUFRZPcT2GGje28YWMMbmGlQgCJLV9oFHdBD4IeYGaDYrCvB2wdKkrJhhjTC5hiSBAUtsHau3+lVZJH8IbM6BIEWjSJKhxGWNMelY1FCB//eWmGqi06DuXAFq0CHZIxhiTIUsEAfLXX1CrliLTpsL110N4eLBDMsaYDFkiCIBdu1xTQK3yB2HjRrj55mCHZIwxmbJEkM3WrYMrr4QDB+D+6nPcwtatgxuUMcachiWCbPbuu65E8MsvcH3CDxARAVWrBjssY4zJlCWCbJSSApMmQZs2EBkJLFvmJp6xOQeMMbmYJYJsFBXlhppu3x5IToYVK7zpyIwxJveyRJCNJk50Nwzfcguwfr0bf9oSgTEml7NEkI0mTnS3C5QuDSxf7hZaIjDG5HKWCLLJrl2wcqVrHwBcIggJscHljDG5niWCbBIV5X43auQtWL4catVys9EYY0wuZokgm0RFuc5BDRoASUlubkqrFjLGnAMsEWST6Gi49FIoXhz45BOIjYU77wx2WMYYc0aWCLKBqisRREbipiLr29d1HerYMdihGWPMGVkiyAaxsbBjhxtagm++gfh4+Owzu5HMGHNOsESQDVIbiq+8EldHVLs2XHBBUGMyxhh/WSLIBj/+CGFhUPcKdY3EDRsGOyRjjPFbQBOBiLQWkb9EZJ2IvJDB+mdEZKWILBeR2SJyzl1Gx8XBkCHQvTuE74lzdUSWCIwx55CAJQIRCQU+A9oAtYEuIpL+7qolQKSqXgH8D/hvoOIJlHfeccMK/fvfuNIAWCIwxpxTAlkiaASsU9UNqnocGA20991AVeeo6lHv6SKgcgDjyXZ//glffgn33APVq+MSQUgI1KsX7NCMMcZvgUwElYAtPs9jvWWZeQCYltEKEXlYRKJFJHrXrl3ZGOLZO3jQ9Q4tUQLefNNbuHixu5mgSJGgxmaMMVmRKxqLRaQbEAm8k9F6VR2kqpGqGlm2bNmcDS4Tb7zhBhgdMwYqVMB1GY2KsmohY8w5p0AA9x0HVPF5XtlbdhIRuR54CbhGVRMCGE+2mjULmjeHa67BzUhz771u5LkuXYIdmjHGZEkgSwRRQE0RqS4iYcBdwCTfDUSkPvAl0E5VdwYwlmx16JCbnL5ZM2/B55/DuHFunkqbn9gYc44JWCJQ1STgcWAGsAoYq6p/ishrItLO2+wdoBgwTkSWisikTHaXq/z2mysEpCWCiRPh8svhmWeCGpcxxpyNQFYNoapTganplr3s8/j6QL5/oMyf70aPuPpqICEBfv0VHnrIhpQwxpyTckVj8bnm11/dCNMlSuAaiI8dg5Ytgx2WMcaclYCWCPKipCRYuBB63LYfRv0AGza4kkCLFsEOzRhjzoolgixavhyOHIGma4fAqGfcBAR163oTFRtjzLnHqoayaP5897vZumFQtKjrQnTttUGNyRhj/gkrEWTR/PlQpXwiVbYvc+NLJCdDhw7BDssYY86aJYIsUHUNxddU3gjbgeuugxo1gh2WMcb8I1Y1lAUbN8LWrdCMX6BiRbjoomCHZIwx/5iVCLIgtX2g6aZvoVULu2/ABF1iYiKxsbHEx8cHOxSTS4SHh1O5cmUKFizo92ssEWTBL7/AecWSuXzXT3DNZ8EOxxhiY2MpXrw41apVQ+zCJN9TVfbs2UNsbCzVq1f3+3VWNeQnVZg6FVpdvIVQUuy+AZMrxMfHExERYUnAACAiREREZLmEaInAH0eOsOTud4mLg3aFZ0GZMm7eAWNyAUsCxtfZfB+sasgfH33E5G8TEFK4efMXrjRg/3zGmDzCSgSZ2LIFmjSBVb8dhHfeYTK30lh+o9yWxd4kBMaYPXv2UK9ePerVq0f58uWpVKlS2vPjx4+f9rXR0dE8+eSTZ3yPJk2aZFe4JhNWIsjEl1+6MYVefWATr+4vx2IieUtfcCutfcAYACIiIli6dCkA/fr1o1ixYjz33HNp65OSkihQIOPTTGRkJJGRkWd8jwULFmRLrDkpOTmZ0NDQYIfhN0sEGUhOhqFDoUABGPdnbVYVm0bJAtD9gmWwqSTUqRPsEI05Ve/ebsak7FSvHnz4YZZe0qNHD8LDw1myZAlNmzblrrvu4qmnniI+Pp7ChQszZMgQatWqxdy5c3n33XeZMmUK/fr1Y/PmzWzYsIHNmzfTu3fvtNJCsWLFOHz4MHPnzqVfv36UKVOGFStW0LBhQ0aOHImIMHXqVJ555hmKFi1K06ZN2bBhA1OmTDkpro0bN3LPPfdw5MgRAD799NO00saAAQMYOXIkISEhtGnThrfffpt169bRs2dPdu3aRWhoKOPGjWPLli1pMQM8/vjjREZG0qNHD6pVq0bnzp2ZOXMmffr04dChQwwaNIjjx49To0YNRowYQZEiRdixYwc9e/Zkw4YNAAwcOJDp06dTunRpevfuDcBLL71EuXLleOqpp87yD5c1lggy8OOPEBcHn/XbybP9irP88IUMHw4VGn0I27fDOZTpjQmG2NhYFixYQGhoKAcPHuSXX36hQIECzJo1ixdffJHvvvvulNesXr2aOXPmcOjQIWrVqkWvXr1O6Qu/ZMkS/vzzTypWrEjTpk359ddfiYyM5JFHHuHnn3+mevXqdMlkuthy5coxc+ZMwsPDWbt2LV26dCE6Oppp06YxceJEfvvtN4oUKcLevXsBuPvuu3nhhRfo0KED8fHxpKSksGXLltN+7oiICGJiYgBXbfbQQw8B0LdvXwYPHswTTzzBk08+yTXXXMP48eNJTk7m8OHDVKxYkY4dO9K7d29SUlIYPXo0v//+e5aP+9myRJCBwYNdx6AHS/yPRP5i032v0q1bSZBaUKtWsMMzJmNZvHIPpDvvvDOtauTAgQN0796dtWvXIiIkJiZm+JpbbrmFQoUKUahQIcqVK8eOHTuoXLnySds0atQobVm9evXYuHEjxYoV48ILL0zrN9+lSxcGDRp0yv4TExN5/PHHWbp0KaGhoaxZswaAWbNmcd9991GkSBEASpcuzaFDh4iLi6ODN45YeHi4X5+7c+fOaY9XrFhB37592b9/P4cPH+amm24C4KeffmL48OEAhIaGUqJECUqUKEFERARLlixhx44d1K9fn4iICL/eMztYIkhn1y6YNAkefxzCZv7AUzXWwDcfBTssY84pRYsWTXv8n//8h5YtWzJ+/Hg2btzItZmM1luoUKG0x6GhoSQlJZ3VNpn54IMPOP/881m2bBkpKSl+n9x9FShQgJSUlLTn6fvr+37uHj16MGHCBOrWrcvQoUOZO3fuaff94IMPMnToULZv387999+f5dj+Ces1lM6oUZCYCPffnQBz5kCbNsEOyZhz2oEDB6hUqRIAQ4cOzfb916pViw0bNrBx40YAxowZk2kcFSpUICQkhBEjRpCcnAzADTfcwJAhQzh69CgAe/fupXjx4lSuXJkJEyYAkJCQwNGjR7ngggtYuXIlCQkJ7N+/n9mzZ2ca16FDh6hQoQKJiYmMGjUqbXmrVq0YOHAg4BqVDxw4AECHDh2YPn06UVFRaaWHnGKJwIeqqxZq1AguXzfBTUF5883BDsuYc1qfPn3497//Tf369bN0Be+vwoUL8/nnn9O6dWsaNmxI8eLFKVGixCnbPfroowwbNoy6deuyevXqtKv31q1b065dOyIjI6lXrx7vvvsuACNGjODjjz/miiuuoEmTJmzfvp0qVarQqVMnLr/8cjp16kT9+vUzjat///5cddVVNG3alEsuuSRt+UcffcScOXOoU6cODRs2ZOXKlQCEhYXRsmVLOnXqlOM9jkRVc/QN/6nIyEiNjo4OyL5//RWaNYMvBiqPfNnAJYKVKyHE8qXJnVatWsWldpc7hw8fplixYqgqjz32GDVr1uTpp58OdlhZkpKSQoMGDRg3bhw1a9b8R/vK6HshIotVNcP+unaG86hCnz5Qrhx0LTvTdcN7/nlLAsacA7766ivq1avHZZddxoEDB3jkkUeCHVKWrFy5kho1atCqVat/nATOhpUIPGPHQufOMKjfVh4a0QISEmD9eggLy/b3Mia7WInAZCSrJQLrNQQsXgyPPgpXXBzP/e9cCkXDYfx4SwLGmHwh3yeCP/+Eli0hIgK+u+xlQuOSIToaqlQJdmjGGJMj8n0F+Ht9dpByLJ75ny6lxg8fQY8elgSMMflKvk4EBz4exuipxemaNJxK7RrC8ePgx2iIxhiTl+TbRJC4ZAUje0dzjCI88nUjqFwZ7rwTLr442KEZc85o2bIlM2bMOGnZhx9+SK9evTJ9zbXXXktqh4+bb76Z/fv3n7JNv3790vrzZ2bChAlpffABXn75ZWbNmpWF6E2qfJkIvv5KKdLwEh7XT2hYN4mGD9RzPYR87v4zxpxZly5dGD169EnLRo8enenAb+lNnTqVkiVLntV7p08Er732Gtdff/1Z7StYUu9uDrZ811i8ciU88VgyjfQ3rr8lnPavNXQrMhkz3ZhzRTBGob7jjjvo27cvx48fJywsjI0bN7J161aaN29Or169iIqK4tixY9xxxx28+uqrp7y+WrVqREdHU6ZMGd544w2GDRtGuXLlqFKlCg0buv/Nr7766pThnJcuXcqkSZOYN28er7/+Ot999x39+/enbdu23HHHHcyePZvnnnuOpKQkrrzySgYOHEihQoWoVq0a3bt3Z/LkySQmJjJu3LiT7vqF/Dlcdb4qERw7Bl3vSqZY8gG+u+I1Xp1YjwYNgh2VMeeu0qVL06hRI6ZNmwa40kCnTp0QEd544w2io6NZvnw58+bNY/ny5ZnuZ/HixYwePZqlS5cydepUoqKi0tZ17NiRqKgoli1bxqWXXsrgwYNp0qQJ7dq145133mHp0qVcdNFFadvHx8fTo0cPxowZwx9//EFSUlLa2D4AZcqUISYmhl69emVY/ZQ6XHVMTAxjxoxJmxfBd7jqZcuW0adPH8ANV/3YY4+xbNkyFixYQIUKFc543FKHq77rrrsy/HxA2nDVy5YtIyYmhssuu4z7778/beTS1OGqu3Xrdsb3O5N8dRn8xBOw7I9QJtOd8oNes3kFTJ4SrFGoU6uH2rdvz+jRo9NOZGPHjmXQoEEkJSWxbds2Vq5cyRVXXJHhPn755Rc6dOiQNhR0u3bt0tZlNpxzZv766y+qV6/OxV57X/fu3fnss8/SrqI7duwIQMOGDfn+++9PeX1+HK463ySCwYPdz0vyJm3vLw9XXRXskIzJE9q3b8/TTz9NTEwMR48epWHDhvz999+8++67REVFUapUKXr06HHKkM3+yupwzmeSOpR1ZsNY58fhqvNN1VCdy5Ue5afz6nnvwVtvBTscY/KMYsWK0bJlS+6///60RuKDBw9StGhRSpQowY4dO9KqjjLTokULJkyYwLFjxzh06BCTJ09OW5fZcM7Fixfn0KFDp+yrVq1abNy4kXXr1gFuFNFrrrnG78+TH4erDmgiEJHWIvKXiKwTkRcyWF9IRMZ4638TkWqBiqXRpnEM2d6G0Df7Q9mygXobY/KlLl26sGzZsrREULduXerXr88ll1xC165dadq06Wlf36BBAzp37kzdunVp06YNV155Zdq6zIZzvuuuu3jnnXeoX78+69evT1seHh7OkCFDuPPOO6lTpw4hISH07NnT78+SH4erDtigcyISCqwBbgBigSigi6qu9NnmUeAKVe0pIncBHVS1c4Y79Jz1oHPTp8MXX8B331nbgMkzbNC5/Mef4apz0zDUjYB1qrpBVY8Do4H26bZpDwzzHv8PaCUiEpBoWreGCRMsCRhjzlmBGq46kI3FlYAtPs9jgfQttGnbqGqSiBwAIoDdvhuJyMPAwwBVq1YNVLzGGJOr1a5dO+2+gux0TjQWq+ogVY1U1ciyVr9vzEnOtTlFTGCdzfchkIkgDvAdxrOytyzDbUSkAFAC2BPAmIzJU8LDw9mzZ48lAwO4JLBnz54sd3kNZNVQFFBTRKrjTvh3AV3TbTMJ6A4sBO4AflL7Rhvjt8qVKxMbG8uuXbuCHYrJJcLDw6lcuXKWXhOwRODV+T8OzABCgW9U9U8ReQ2IVtVJwGBghIisA/bikoUxxk8FCxakevXqwQ7DnOMCemexqk4FpqZb9rLP43jgzkDGYIwx5vTOicZiY4wxgWOJwBhj8rmA3VkcKCKyC9h0Fi8tQ7r7E3IJiytrcmtckHtjs7iyJrfGBf8stgtUNcP+9+dcIjhbIhKd2e3VwWRxZU1ujQtyb2wWV9bk1rggcLFZ1ZAxxuRzlgiMMSafy0+JYFCwA8iExZU1uTUuyL2xWVxZk1vjggDFlm/aCIwxxmQsP5UIjDHGZMASgTHG5HN5PhGcabrMHIyjiojMEZGVIvKniDzlLe8nInEistT7uTlI8W0UkT+8GKK9ZaVFZKaIrPV+l8rhmGr5HJelInJQRHoH45iJyDcislNEVvgsy/D4iPOx951bLiINghDbOyKy2nv/8SJS0lteTUSO+Ry7L3I4rkz/diLyb++Y/SUi2TMZr/9xjfGJaaOILPWW5+TxyuwcEfjvmarm2R/cYHfrgQuBMGAZUDtIsVQAGniPi+Om8awN9AOeywXHaiNQJt2y/wIveI9fAAYE+W+5HbggGMcMaAE0AFac6fgANwPTAAGuBn4LQmw3AgW8xwN8Yqvmu10Q4srwb+f9LywDCgHVvf/b0JyKK93694CXg3C8MjtHBPx7ltdLBP5Ml5kjVHWbqsZ4jw8Bq3AztOVmvlOJDgNuC14otALWq+rZ3FX+j6nqz7gRcn1ldnzaA8PVWQSUFJEKORmbqv6oqkne00W4+UByVCbHLDPtgdGqmqCqfwPrcP+/ORqXN1VuJ+DbQLz36ZzmHBHw71leTwQZTZcZ9JOviFQD6gO/eYse94p23+R09YsPBX4UkcXipgYFOF9Vt3mPtwPnByc0wA1R7vvPmRuOWWbHJ7d97+7HXTmmqi4iS0Rknog0D0I8Gf3tcssxaw7sUNW1Psty/HilO0cE/HuW1xNBriMixYDvgN6qehAYCFwE1AO24YqlwdBMVRsAbYDHRKSF70p1ZdGg9DUWkTCgHTDOW5RbjlmaYB6f0xGRl4AkYJS3aBtQVVXrA88A/yci5+VgSLnub5dOF06+4Mjx45XBOSJNoL5neT0R+DNdZo4RkYK4P/AoVf0eQFV3qGqyqqYAXxGg4vCZqGqc93snMN6LY0dqUdP7vTMYseGSU4yq7vBizBXHjMyPT6743olID6AtcLd3AsGretnjPV6Mq4u/OKdiOs3fLujHTNx0uR2BManLcvp4ZXSOIAe+Z3k9EaRNl+ldVd6Fmx4zx3l1j4OBVar6vs9y3zq9DsCK9K/NgdiKikjx1Me4hsYVnJhKFO/3xJyOzXPSVVpuOGaezI7PJOBer1fH1cABn6J9jhCR1kAfoJ2qHvVZXlZEQr3HFwI1gQ05GFdmf7tJwF0iUkjc9LY1gd9zKi7P9cBqVY1NXZCTxyuzcwQ58T3LidbwYP7gWtbX4DL5S0GMoxmuSLccWOr93AyMAP7wlk8CKgQhtgtxPTaWAX+mHicgApgNrAVmAaWDEFtRYA9QwmdZjh8zXCLaBiTi6mIfyOz44HpxfOZ95/4AIoMQ2zpc/XHqd+0Lb9vbvb/xUiAGuDWH48r0bwe85B2zv4A2ORmXt3wo0DPdtjl5vDI7RwT8e2ZDTBhjTD6X16uGjDHGnIElAmOMyecsERhjTD5nicAYY/I5SwTGGJPPWSIwxiMiyXLyaKfZNlqtN4plsO53MOa0CgQ7AGNykWOqWi/YQRiT06xEYMwZeOPT/1fcfA2/i0gNb3k1EfnJG0BttohU9ZafL24OgGXeTxNvV6Ei8pU31vyPIlLY2/5Jbwz65SIyOkgf0+RjlgiMOaFwuqqhzj7rDqhqHeBT4ENv2SfAMFW9Ajeo28fe8o+BeapaFzfu/Z/e8prAZ6p6GbAfd9cquDHm63v76RmYj2ZM5uzOYmM8InJYVYtlsHwjcJ2qbvAGBduuqhEishs3REKit3ybqpYRkV1AZVVN8NlHNWCmqtb0nj8PFFTV10VkOnAYmABMUNXDAf6oxpzESgTG+EczeZwVCT6PkznRRncLbsyYBkCUNwqmMTnGEoEx/uns83uh93gBbkRbgLuBX7zHs4FeACISKiIlMtupiIQAVVR1DvA8UAI4pVRiTCDZlYcxJxQWb9Jyz3RVTe1CWkpEluOu6rt4y54AhojIv4BdwH3e8qeAQSLyAO7KvxdutMuMhAIjvWQhwMequj+bPo8xfrE2AmPOwGsjiFTV3cGOxZhAsKohY4zJ56xEYIwx+ZyVCIwxJp+zRGCMMfmcJQJjjMnnLBEYY0w+Z4nAGGPyuf8HaVKP4kw2WHkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "printplt(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2343f072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31270 images belonging to 1595 classes.\n",
      "978/978 [==============================] - 1015s 1s/step - loss: 1.2582 - acc: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2581865787506104, 0.8460185527801514]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = 'D:\\\\aligned_images_DB_dataset\\\\test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        directory = test_dir,\n",
    "        target_size=(152, 152),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17657fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:\\\\saved_model\\\\DF_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "818d7292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [15.901619911193848,\n",
       "  13.268969535827637,\n",
       "  12.940574645996094,\n",
       "  12.724366188049316,\n",
       "  12.310381889343262,\n",
       "  12.393536567687988,\n",
       "  12.335624694824219,\n",
       "  11.607147216796875,\n",
       "  11.768202781677246,\n",
       "  11.279566764831543,\n",
       "  11.240436553955078,\n",
       "  11.427748680114746,\n",
       "  10.451411247253418,\n",
       "  10.236285209655762,\n",
       "  10.097569465637207,\n",
       "  10.083492279052734,\n",
       "  9.871195793151855,\n",
       "  9.336426734924316,\n",
       "  9.229304313659668,\n",
       "  9.128613471984863,\n",
       "  9.23123836517334,\n",
       "  9.051065444946289,\n",
       "  8.5697660446167,\n",
       "  7.984318733215332,\n",
       "  8.208353042602539,\n",
       "  7.586956024169922,\n",
       "  7.49091911315918,\n",
       "  7.5271172523498535,\n",
       "  7.501169204711914,\n",
       "  7.1305670738220215,\n",
       "  6.870749473571777,\n",
       "  7.095653533935547,\n",
       "  6.668389320373535,\n",
       "  6.323411464691162,\n",
       "  6.19749641418457,\n",
       "  5.950539588928223,\n",
       "  5.2806267738342285,\n",
       "  6.137842178344727,\n",
       "  5.388761520385742,\n",
       "  5.120344638824463,\n",
       "  5.593967437744141,\n",
       "  5.006410598754883,\n",
       "  5.143662929534912,\n",
       "  4.624812602996826,\n",
       "  4.5728230476379395,\n",
       "  4.851795196533203,\n",
       "  4.826474189758301,\n",
       "  4.459602355957031,\n",
       "  4.386640548706055,\n",
       "  4.305243015289307,\n",
       "  3.7063405513763428,\n",
       "  4.475019931793213,\n",
       "  3.9154677391052246,\n",
       "  3.6958534717559814,\n",
       "  3.714637041091919,\n",
       "  3.5939133167266846,\n",
       "  3.582486867904663,\n",
       "  3.45097017288208,\n",
       "  3.399526357650757,\n",
       "  3.2061541080474854,\n",
       "  2.8867311477661133,\n",
       "  3.1891281604766846,\n",
       "  2.9275336265563965,\n",
       "  2.728665828704834,\n",
       "  3.006455421447754,\n",
       "  2.7797446250915527,\n",
       "  2.797206163406372,\n",
       "  2.695138454437256,\n",
       "  2.5945441722869873,\n",
       "  2.478881597518921,\n",
       "  2.693514108657837,\n",
       "  2.7052597999572754,\n",
       "  2.3858001232147217,\n",
       "  2.3937082290649414,\n",
       "  2.2942757606506348,\n",
       "  2.3473849296569824,\n",
       "  2.383910655975342,\n",
       "  2.2724833488464355,\n",
       "  2.275993585586548,\n",
       "  2.2292542457580566,\n",
       "  2.2117769718170166,\n",
       "  1.952197551727295,\n",
       "  2.0997562408447266,\n",
       "  1.8963567018508911,\n",
       "  2.0780625343322754,\n",
       "  1.9030776023864746,\n",
       "  1.7949838638305664,\n",
       "  1.7784676551818848,\n",
       "  1.9178234338760376,\n",
       "  1.9227582216262817,\n",
       "  1.744893193244934,\n",
       "  1.7184786796569824,\n",
       "  1.6345431804656982,\n",
       "  1.6481715440750122,\n",
       "  1.7961474657058716,\n",
       "  1.7663400173187256,\n",
       "  1.5623254776000977,\n",
       "  1.552051067352295,\n",
       "  1.601036548614502,\n",
       "  1.507704734802246,\n",
       "  1.4332302808761597,\n",
       "  1.5187753438949585,\n",
       "  1.3690025806427002,\n",
       "  1.3440262079238892,\n",
       "  1.3585810661315918,\n",
       "  1.372685432434082,\n",
       "  1.3230934143066406,\n",
       "  1.264050006866455,\n",
       "  1.3207635879516602,\n",
       "  1.353257656097412,\n",
       "  1.3035011291503906,\n",
       "  1.38295578956604,\n",
       "  1.5558667182922363,\n",
       "  1.5075401067733765,\n",
       "  1.2818182706832886,\n",
       "  1.2573425769805908,\n",
       "  1.3490654230117798,\n",
       "  1.2354564666748047,\n",
       "  1.2092268466949463,\n",
       "  1.222804307937622,\n",
       "  1.1510132551193237,\n",
       "  1.5537428855895996,\n",
       "  1.295194387435913,\n",
       "  1.188742756843567,\n",
       "  1.1852235794067383,\n",
       "  1.1967743635177612,\n",
       "  1.2236655950546265,\n",
       "  1.2789075374603271,\n",
       "  1.134846806526184,\n",
       "  1.1824418306350708,\n",
       "  1.2490538358688354,\n",
       "  1.3105746507644653,\n",
       "  1.1680642366409302,\n",
       "  1.0991203784942627,\n",
       "  1.1395490169525146,\n",
       "  1.0967463254928589,\n",
       "  1.1713783740997314,\n",
       "  1.0487982034683228,\n",
       "  1.1215683221817017,\n",
       "  1.2046645879745483,\n",
       "  1.151586651802063,\n",
       "  1.0658700466156006,\n",
       "  0.9540358781814575,\n",
       "  1.0333060026168823,\n",
       "  0.9596715569496155,\n",
       "  1.0056123733520508,\n",
       "  1.0680177211761475,\n",
       "  0.959644615650177,\n",
       "  1.0000287294387817,\n",
       "  0.9546676874160767,\n",
       "  0.9446789026260376,\n",
       "  0.9247505068778992,\n",
       "  0.9264509081840515,\n",
       "  0.9023873805999756,\n",
       "  0.896487832069397,\n",
       "  1.134598970413208,\n",
       "  1.000421166419983,\n",
       "  1.0670496225357056,\n",
       "  1.108461618423462,\n",
       "  1.0408432483673096,\n",
       "  0.8577402234077454,\n",
       "  0.9110442399978638,\n",
       "  0.8909862041473389,\n",
       "  0.8249855637550354,\n",
       "  0.9573757648468018,\n",
       "  0.8717572093009949,\n",
       "  1.003842830657959,\n",
       "  0.9506778120994568,\n",
       "  0.8379887938499451,\n",
       "  0.8714590668678284,\n",
       "  0.8853263854980469,\n",
       "  0.9930574893951416,\n",
       "  0.8632360100746155,\n",
       "  0.9392261505126953,\n",
       "  1.0006890296936035,\n",
       "  1.0052180290222168,\n",
       "  0.8850281238555908,\n",
       "  0.9902033805847168,\n",
       "  0.85108482837677,\n",
       "  0.8832468390464783,\n",
       "  1.101745367050171,\n",
       "  0.9461763501167297,\n",
       "  0.9086341261863708,\n",
       "  0.9801461100578308,\n",
       "  0.8442766070365906,\n",
       "  0.8814639449119568,\n",
       "  0.9195181131362915,\n",
       "  0.8254643082618713,\n",
       "  0.8710595965385437,\n",
       "  0.8631079196929932,\n",
       "  0.8039087653160095,\n",
       "  0.819437563419342,\n",
       "  0.8849781155586243,\n",
       "  0.7668666243553162,\n",
       "  0.7640601396560669,\n",
       "  0.7964957356452942,\n",
       "  0.8054704070091248,\n",
       "  0.7046034336090088,\n",
       "  0.7390873432159424,\n",
       "  0.7833889126777649],\n",
       " 'acc': [0.011874999850988388,\n",
       "  0.023749999701976776,\n",
       "  0.036249998956918716,\n",
       "  0.04749999940395355,\n",
       "  0.05312500149011612,\n",
       "  0.046875,\n",
       "  0.06312499940395355,\n",
       "  0.06875000149011612,\n",
       "  0.08375000208616257,\n",
       "  0.10875000059604645,\n",
       "  0.12250000238418579,\n",
       "  0.10562500357627869,\n",
       "  0.13437500596046448,\n",
       "  0.16374999284744263,\n",
       "  0.15625,\n",
       "  0.18437500298023224,\n",
       "  0.19249999523162842,\n",
       "  0.22812500596046448,\n",
       "  0.23937499523162842,\n",
       "  0.2787500023841858,\n",
       "  0.3031249940395355,\n",
       "  0.3087500035762787,\n",
       "  0.30562499165534973,\n",
       "  0.33812499046325684,\n",
       "  0.3618749976158142,\n",
       "  0.3981249928474426,\n",
       "  0.4025000035762787,\n",
       "  0.4256249964237213,\n",
       "  0.4337500035762787,\n",
       "  0.44624999165534973,\n",
       "  0.4387499988079071,\n",
       "  0.4518750011920929,\n",
       "  0.46000000834465027,\n",
       "  0.4793750047683716,\n",
       "  0.5231249928474426,\n",
       "  0.5375000238418579,\n",
       "  0.5350000262260437,\n",
       "  0.53125,\n",
       "  0.5643749833106995,\n",
       "  0.5774999856948853,\n",
       "  0.5575000047683716,\n",
       "  0.5606250166893005,\n",
       "  0.5924999713897705,\n",
       "  0.6168749928474426,\n",
       "  0.6318749785423279,\n",
       "  0.6212499737739563,\n",
       "  0.6087499856948853,\n",
       "  0.6206250190734863,\n",
       "  0.6187499761581421,\n",
       "  0.6200000047683716,\n",
       "  0.6518750190734863,\n",
       "  0.6331250071525574,\n",
       "  0.6524999737739563,\n",
       "  0.6656249761581421,\n",
       "  0.659375011920929,\n",
       "  0.6537500023841858,\n",
       "  0.6856250166893005,\n",
       "  0.6850000023841858,\n",
       "  0.6943749785423279,\n",
       "  0.7074999809265137,\n",
       "  0.7124999761581421,\n",
       "  0.6968749761581421,\n",
       "  0.7099999785423279,\n",
       "  0.7300000190734863,\n",
       "  0.706250011920929,\n",
       "  0.71875,\n",
       "  0.7337499856948853,\n",
       "  0.7243750095367432,\n",
       "  0.7418749928474426,\n",
       "  0.7543749809265137,\n",
       "  0.746874988079071,\n",
       "  0.7318750023841858,\n",
       "  0.7524999976158142,\n",
       "  0.7749999761581421,\n",
       "  0.7487499713897705,\n",
       "  0.7587500214576721,\n",
       "  0.7681249976158142,\n",
       "  0.7643749713897705,\n",
       "  0.7593749761581421,\n",
       "  0.7524999976158142,\n",
       "  0.7718750238418579,\n",
       "  0.7912499904632568,\n",
       "  0.7756249904632568,\n",
       "  0.7887499928474426,\n",
       "  0.7712500095367432,\n",
       "  0.7799999713897705,\n",
       "  0.8025000095367432,\n",
       "  0.7993749976158142,\n",
       "  0.7962499856948853,\n",
       "  0.8037499785423279,\n",
       "  0.7981250286102295,\n",
       "  0.8206250071525574,\n",
       "  0.8131250143051147,\n",
       "  0.8237500190734863,\n",
       "  0.7975000143051147,\n",
       "  0.8174999952316284,\n",
       "  0.8206250071525574,\n",
       "  0.8293750286102295,\n",
       "  0.8106250166893005,\n",
       "  0.8324999809265137,\n",
       "  0.8393750190734863,\n",
       "  0.8231250047683716,\n",
       "  0.8387500047683716,\n",
       "  0.84375,\n",
       "  0.8506249785423279,\n",
       "  0.84375,\n",
       "  0.8393750190734863,\n",
       "  0.8493750095367432,\n",
       "  0.8550000190734863,\n",
       "  0.8487499952316284,\n",
       "  0.8337500095367432,\n",
       "  0.8362500071525574,\n",
       "  0.8112499713897705,\n",
       "  0.8262500166893005,\n",
       "  0.8331249952316284,\n",
       "  0.8543750047683716,\n",
       "  0.8387500047683716,\n",
       "  0.8450000286102295,\n",
       "  0.8731250166893005,\n",
       "  0.8675000071525574,\n",
       "  0.8700000047683716,\n",
       "  0.8374999761581421,\n",
       "  0.8299999833106995,\n",
       "  0.8637499809265137,\n",
       "  0.8612499833106995,\n",
       "  0.8600000143051147,\n",
       "  0.8518750071525574,\n",
       "  0.8518750071525574,\n",
       "  0.8668749928474426,\n",
       "  0.8606250286102295,\n",
       "  0.8656250238418579,\n",
       "  0.8362500071525574,\n",
       "  0.8537499904632568,\n",
       "  0.8731250166893005,\n",
       "  0.8862500190734863,\n",
       "  0.871874988079071,\n",
       "  0.8693749904632568,\n",
       "  0.8700000047683716,\n",
       "  0.8737499713897705,\n",
       "  0.856249988079071,\n",
       "  0.8606250286102295,\n",
       "  0.8693749904632568,\n",
       "  0.8956249952316284,\n",
       "  0.8837500214576721,\n",
       "  0.8924999833106995,\n",
       "  0.8918750286102295,\n",
       "  0.8706250190734863,\n",
       "  0.8962500095367432,\n",
       "  0.8849999904632568,\n",
       "  0.8962500095367432,\n",
       "  0.8887500166893005,\n",
       "  0.9043750166893005,\n",
       "  0.9043750166893005,\n",
       "  0.903124988079071,\n",
       "  0.8999999761581421,\n",
       "  0.8650000095367432,\n",
       "  0.8824999928474426,\n",
       "  0.8756250143051147,\n",
       "  0.8700000047683716,\n",
       "  0.890625,\n",
       "  0.9156249761581421,\n",
       "  0.8987500071525574,\n",
       "  0.8999999761581421,\n",
       "  0.909375011920929,\n",
       "  0.8787500262260437,\n",
       "  0.9043750166893005,\n",
       "  0.8943750262260437,\n",
       "  0.8899999856948853,\n",
       "  0.9137499928474426,\n",
       "  0.8943750262260437,\n",
       "  0.8943750262260437,\n",
       "  0.8812500238418579,\n",
       "  0.9075000286102295,\n",
       "  0.90625,\n",
       "  0.8662499785423279,\n",
       "  0.8762500286102295,\n",
       "  0.8949999809265137,\n",
       "  0.8837500214576721,\n",
       "  0.8862500190734863,\n",
       "  0.90625,\n",
       "  0.871874988079071,\n",
       "  0.890625,\n",
       "  0.8949999809265137,\n",
       "  0.875,\n",
       "  0.9106249809265137,\n",
       "  0.9112499952316284,\n",
       "  0.8793749809265137,\n",
       "  0.9137499928474426,\n",
       "  0.8981249928474426,\n",
       "  0.9112499952316284,\n",
       "  0.9150000214576721,\n",
       "  0.9143750071525574,\n",
       "  0.8856250047683716,\n",
       "  0.9150000214576721,\n",
       "  0.9293749928474426,\n",
       "  0.9156249761581421,\n",
       "  0.9131249785423279,\n",
       "  0.9275000095367432,\n",
       "  0.9231250286102295,\n",
       "  0.9112499952316284],\n",
       " 'val_loss': [13.37374210357666,\n",
       "  12.654867172241211,\n",
       "  12.329046249389648,\n",
       "  12.044074058532715,\n",
       "  11.846963882446289,\n",
       "  11.498044967651367,\n",
       "  11.140052795410156,\n",
       "  10.956416130065918,\n",
       "  10.769617080688477,\n",
       "  10.437336921691895,\n",
       "  10.286301612854004,\n",
       "  10.116442680358887,\n",
       "  9.6535062789917,\n",
       "  9.483926773071289,\n",
       "  9.20396900177002,\n",
       "  8.954326629638672,\n",
       "  8.68429946899414,\n",
       "  8.395920753479004,\n",
       "  8.281393051147461,\n",
       "  7.923018455505371,\n",
       "  8.046274185180664,\n",
       "  7.6932830810546875,\n",
       "  7.355440616607666,\n",
       "  7.127591609954834,\n",
       "  7.007291316986084,\n",
       "  6.774683952331543,\n",
       "  6.50480842590332,\n",
       "  6.329532623291016,\n",
       "  6.186908721923828,\n",
       "  5.932606220245361,\n",
       "  5.824958801269531,\n",
       "  5.824064254760742,\n",
       "  5.527246952056885,\n",
       "  5.391634941101074,\n",
       "  5.239344120025635,\n",
       "  5.159940719604492,\n",
       "  4.893820285797119,\n",
       "  4.859659194946289,\n",
       "  4.762696266174316,\n",
       "  4.597996234893799,\n",
       "  4.668243885040283,\n",
       "  4.387905120849609,\n",
       "  4.361997604370117,\n",
       "  4.179197311401367,\n",
       "  4.14126443862915,\n",
       "  4.064978122711182,\n",
       "  4.018006324768066,\n",
       "  3.923072576522827,\n",
       "  3.900041103363037,\n",
       "  3.779726028442383,\n",
       "  3.596287250518799,\n",
       "  3.691237688064575,\n",
       "  3.5346908569335938,\n",
       "  3.391641616821289,\n",
       "  3.3669636249542236,\n",
       "  3.2179670333862305,\n",
       "  3.2467470169067383,\n",
       "  3.197392225265503,\n",
       "  3.1309473514556885,\n",
       "  3.036092519760132,\n",
       "  2.889591693878174,\n",
       "  2.9837591648101807,\n",
       "  2.800802230834961,\n",
       "  2.774374008178711,\n",
       "  2.814455509185791,\n",
       "  2.7286758422851562,\n",
       "  2.6527903079986572,\n",
       "  2.629956007003784,\n",
       "  2.541858196258545,\n",
       "  2.5147716999053955,\n",
       "  2.554028034210205,\n",
       "  2.5253844261169434,\n",
       "  2.401844024658203,\n",
       "  2.36850643157959,\n",
       "  2.32334303855896,\n",
       "  2.3261730670928955,\n",
       "  2.276700258255005,\n",
       "  2.2167625427246094,\n",
       "  2.2863051891326904,\n",
       "  2.1617932319641113,\n",
       "  2.162630796432495,\n",
       "  2.03999400138855,\n",
       "  2.141166925430298,\n",
       "  2.0621676445007324,\n",
       "  2.0055439472198486,\n",
       "  2.0202462673187256,\n",
       "  1.9679962396621704,\n",
       "  1.9615894556045532,\n",
       "  1.917050838470459,\n",
       "  1.9065229892730713,\n",
       "  1.8255137205123901,\n",
       "  1.8299013376235962,\n",
       "  1.816272497177124,\n",
       "  1.7889680862426758,\n",
       "  1.7791237831115723,\n",
       "  1.7499449253082275,\n",
       "  1.6863962411880493,\n",
       "  1.676506519317627,\n",
       "  1.7041151523590088,\n",
       "  1.6569308042526245,\n",
       "  1.595962643623352,\n",
       "  1.5756419897079468,\n",
       "  1.5928573608398438,\n",
       "  1.5442196130752563,\n",
       "  1.5237758159637451,\n",
       "  1.5672167539596558,\n",
       "  1.5008554458618164,\n",
       "  1.5084868669509888,\n",
       "  1.5463019609451294,\n",
       "  1.4965637922286987,\n",
       "  1.531835675239563,\n",
       "  1.5676096677780151,\n",
       "  1.5806668996810913,\n",
       "  1.5248503684997559,\n",
       "  1.4107404947280884,\n",
       "  1.4142227172851562,\n",
       "  1.462000846862793,\n",
       "  1.391159176826477,\n",
       "  1.4096115827560425,\n",
       "  1.3725783824920654,\n",
       "  1.348380208015442,\n",
       "  1.51437246799469,\n",
       "  1.3794118165969849,\n",
       "  1.3698691129684448,\n",
       "  1.367289423942566,\n",
       "  1.2775990962982178,\n",
       "  1.3681200742721558,\n",
       "  1.3493053913116455,\n",
       "  1.3069825172424316,\n",
       "  1.3338510990142822,\n",
       "  1.4208612442016602,\n",
       "  1.3207706212997437,\n",
       "  1.2845474481582642,\n",
       "  1.2553153038024902,\n",
       "  1.2576223611831665,\n",
       "  1.2388852834701538,\n",
       "  1.3336272239685059,\n",
       "  1.2675992250442505,\n",
       "  1.2632089853286743,\n",
       "  1.2417486906051636,\n",
       "  1.2450143098831177,\n",
       "  1.2214488983154297,\n",
       "  1.1567497253417969,\n",
       "  1.1792566776275635,\n",
       "  1.1669495105743408,\n",
       "  1.1801893711090088,\n",
       "  1.13759446144104,\n",
       "  1.1673660278320312,\n",
       "  1.131466031074524,\n",
       "  1.1077234745025635,\n",
       "  1.1350442171096802,\n",
       "  1.0918906927108765,\n",
       "  1.0877199172973633,\n",
       "  1.0993993282318115,\n",
       "  1.066709041595459,\n",
       "  1.1767692565917969,\n",
       "  1.1174296140670776,\n",
       "  1.2082687616348267,\n",
       "  1.155409336090088,\n",
       "  1.0941389799118042,\n",
       "  1.0834449529647827,\n",
       "  1.0736591815948486,\n",
       "  1.0488317012786865,\n",
       "  1.03371000289917,\n",
       "  1.0996519327163696,\n",
       "  1.02739679813385,\n",
       "  1.0697050094604492,\n",
       "  1.0646814107894897,\n",
       "  1.0660563707351685,\n",
       "  1.052567958831787,\n",
       "  1.047992467880249,\n",
       "  1.093115210533142,\n",
       "  1.0601977109909058,\n",
       "  1.1503102779388428,\n",
       "  1.0784413814544678,\n",
       "  1.0761818885803223,\n",
       "  1.0583672523498535,\n",
       "  1.0794212818145752,\n",
       "  1.0265599489212036,\n",
       "  1.0570769309997559,\n",
       "  1.1325637102127075,\n",
       "  1.0384074449539185,\n",
       "  1.05846107006073,\n",
       "  1.0386210680007935,\n",
       "  1.026513934135437,\n",
       "  0.9966819286346436,\n",
       "  1.0126663446426392,\n",
       "  1.00316321849823,\n",
       "  1.006813406944275,\n",
       "  0.9805213809013367,\n",
       "  0.9764808416366577,\n",
       "  1.0353596210479736,\n",
       "  1.009223222732544,\n",
       "  0.941146194934845,\n",
       "  0.9465632438659668,\n",
       "  0.9767983555793762,\n",
       "  0.9380460977554321,\n",
       "  0.9005323052406311,\n",
       "  0.9203615188598633,\n",
       "  0.9276469349861145],\n",
       " 'val_acc': [0.021464550867676735,\n",
       "  0.030608566477894783,\n",
       "  0.04065776616334915,\n",
       "  0.040397945791482925,\n",
       "  0.058065760880708694,\n",
       "  0.06465347111225128,\n",
       "  0.0772254467010498,\n",
       "  0.09598283469676971,\n",
       "  0.11417029052972794,\n",
       "  0.09922640770673752,\n",
       "  0.10977847874164581,\n",
       "  0.13324616849422455,\n",
       "  0.1629495471715927,\n",
       "  0.19421185553073883,\n",
       "  0.20335587859153748,\n",
       "  0.2178136557340622,\n",
       "  0.25230276584625244,\n",
       "  0.27520889043807983,\n",
       "  0.281008780002594,\n",
       "  0.32734906673431396,\n",
       "  0.30424177646636963,\n",
       "  0.3279106318950653,\n",
       "  0.36430230736732483,\n",
       "  0.3961848318576813,\n",
       "  0.4053707420825958,\n",
       "  0.4104917347431183,\n",
       "  0.45023593306541443,\n",
       "  0.4522055387496948,\n",
       "  0.4711724519729614,\n",
       "  0.5030633807182312,\n",
       "  0.49616554379463196,\n",
       "  0.4927375912666321,\n",
       "  0.529238224029541,\n",
       "  0.5397316217422485,\n",
       "  0.5584052205085754,\n",
       "  0.5509039163589478,\n",
       "  0.582400918006897,\n",
       "  0.5859294533729553,\n",
       "  0.5804145336151123,\n",
       "  0.604334831237793,\n",
       "  0.5854265689849854,\n",
       "  0.6173677444458008,\n",
       "  0.622606098651886,\n",
       "  0.6349014639854431,\n",
       "  0.6329402327537537,\n",
       "  0.6428301930427551,\n",
       "  0.6480936408042908,\n",
       "  0.6516389846801758,\n",
       "  0.6412125825881958,\n",
       "  0.6542036533355713,\n",
       "  0.6812753081321716,\n",
       "  0.6584948897361755,\n",
       "  0.6747965216636658,\n",
       "  0.6917183995246887,\n",
       "  0.6942663192749023,\n",
       "  0.713115930557251,\n",
       "  0.7039467692375183,\n",
       "  0.7028656005859375,\n",
       "  0.7091767191886902,\n",
       "  0.7158817648887634,\n",
       "  0.7387962937355042,\n",
       "  0.7128980159759521,\n",
       "  0.7468507289886475,\n",
       "  0.7450990080833435,\n",
       "  0.7292248010635376,\n",
       "  0.7399696707725525,\n",
       "  0.7512006163597107,\n",
       "  0.7479235529899597,\n",
       "  0.7616437673568726,\n",
       "  0.7551565766334534,\n",
       "  0.7443111538887024,\n",
       "  0.7521979808807373,\n",
       "  0.7701926827430725,\n",
       "  0.7715001702308655,\n",
       "  0.7724221348762512,\n",
       "  0.7705614566802979,\n",
       "  0.7779369950294495,\n",
       "  0.7840134501457214,\n",
       "  0.7618951797485352,\n",
       "  0.7858154773712158,\n",
       "  0.7817337512969971,\n",
       "  0.8047153353691101,\n",
       "  0.7767804265022278,\n",
       "  0.7889333367347717,\n",
       "  0.8002732396125793,\n",
       "  0.7906346917152405,\n",
       "  0.8002983927726746,\n",
       "  0.7986388802528381,\n",
       "  0.8053104281425476,\n",
       "  0.8039610385894775,\n",
       "  0.8176812529563904,\n",
       "  0.8100458383560181,\n",
       "  0.8121830821037292,\n",
       "  0.8160803914070129,\n",
       "  0.815577507019043,\n",
       "  0.8209750652313232,\n",
       "  0.8338404297828674,\n",
       "  0.8278896808624268,\n",
       "  0.8223663568496704,\n",
       "  0.8275628089904785,\n",
       "  0.8378801941871643,\n",
       "  0.8414925336837769,\n",
       "  0.8330274224281311,\n",
       "  0.8444176316261292,\n",
       "  0.8449205160140991,\n",
       "  0.8341923952102661,\n",
       "  0.8479629158973694,\n",
       "  0.8405789732933044,\n",
       "  0.8324490785598755,\n",
       "  0.8414673805236816,\n",
       "  0.8342427015304565,\n",
       "  0.8266911506652832,\n",
       "  0.8214108943939209,\n",
       "  0.8308566808700562,\n",
       "  0.8541483283042908,\n",
       "  0.8512316346168518,\n",
       "  0.8418780565261841,\n",
       "  0.8560509085655212,\n",
       "  0.8523966670036316,\n",
       "  0.8564280271530151,\n",
       "  0.858799934387207,\n",
       "  0.8204721808433533,\n",
       "  0.8503180742263794,\n",
       "  0.8516255617141724,\n",
       "  0.8521703481674194,\n",
       "  0.8712546229362488,\n",
       "  0.8487256169319153,\n",
       "  0.851256787776947,\n",
       "  0.859931468963623,\n",
       "  0.8557659387588501,\n",
       "  0.8351646661758423,\n",
       "  0.8564364314079285,\n",
       "  0.8631414771080017,\n",
       "  0.8700225353240967,\n",
       "  0.8678433895111084,\n",
       "  0.8679942488670349,\n",
       "  0.8493374586105347,\n",
       "  0.8621189594268799,\n",
       "  0.8615909218788147,\n",
       "  0.8664688467979431,\n",
       "  0.8657397031784058,\n",
       "  0.8699554800987244,\n",
       "  0.8837763071060181,\n",
       "  0.8776914477348328,\n",
       "  0.8765515685081482,\n",
       "  0.8762163519859314,\n",
       "  0.8847569227218628,\n",
       "  0.8747496008872986,\n",
       "  0.8851508498191833,\n",
       "  0.8888469934463501,\n",
       "  0.8797616362571716,\n",
       "  0.8905735611915588,\n",
       "  0.8905400037765503,\n",
       "  0.8881680965423584,\n",
       "  0.8941774964332581,\n",
       "  0.8698381781578064,\n",
       "  0.8852262496948242,\n",
       "  0.8636611104011536,\n",
       "  0.8751100301742554,\n",
       "  0.8873048424720764,\n",
       "  0.8887883424758911,\n",
       "  0.8903975486755371,\n",
       "  0.8943032026290894,\n",
       "  0.8974629640579224,\n",
       "  0.8828040361404419,\n",
       "  0.8975635766983032,\n",
       "  0.8880675435066223,\n",
       "  0.8919899463653564,\n",
       "  0.8877490162849426,\n",
       "  0.889307975769043,\n",
       "  0.8903304934501648,\n",
       "  0.8802226185798645,\n",
       "  0.8893833756446838,\n",
       "  0.86952805519104,\n",
       "  0.8826531767845154,\n",
       "  0.8828962445259094,\n",
       "  0.8857794404029846,\n",
       "  0.8813456892967224,\n",
       "  0.8945462703704834,\n",
       "  0.8869779706001282,\n",
       "  0.8707433342933655,\n",
       "  0.8915876746177673,\n",
       "  0.885947048664093,\n",
       "  0.8895090818405151,\n",
       "  0.8929119110107422,\n",
       "  0.8990386724472046,\n",
       "  0.8948731422424316,\n",
       "  0.894739031791687,\n",
       "  0.8958705067634583,\n",
       "  0.8996086120605469,\n",
       "  0.9011507630348206,\n",
       "  0.8862152695655823,\n",
       "  0.8949317932128906,\n",
       "  0.9087358713150024,\n",
       "  0.9061711430549622,\n",
       "  0.8975132703781128,\n",
       "  0.9081994295120239,\n",
       "  0.9146446585655212,\n",
       "  0.9106300473213196,\n",
       "  0.9078725576400757]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91523cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7126875004172325 0.9293749928474426 0.7210596082173288 0.9146446585655212\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(statistics.mean(training_history.history['acc']), max(training_history.history['acc']), \n",
    "     statistics.mean(training_history.history['val_acc']), max(training_history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724dfad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
